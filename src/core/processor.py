"""
–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏ –∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
"""

import os
import sys
import gc
import hashlib
import datetime
import asyncio
import time
import threading
import psutil
import tracemalloc
import traceback
import json
import signal
import platform
from typing import List, Tuple, Set, Dict, Any, Optional, Deque
from concurrent.futures import ThreadPoolExecutor
from collections import deque

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from .config import Config
from .models import ProcessingMetrics, FaceRecord
from .data_parser import parse_batch_records, get_global_parser
from .checkpoint_manager import CheckpointManager
from .statistics import StatisticsAnalyzer
try:
    # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –ø–∞–ø–∫–∏ src
    from processing.image_processor import ImageProcessorWithEmbedding, process_images_batch
except ImportError:
    # –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–∑ –∫–æ—Ä–Ω—è
    from src.processing.image_processor import ImageProcessorWithEmbedding, process_images_batch
from src.utils.logger import setup_logging
from src.utils.memory_monitor import MemoryMonitor
from src.utils.windows_paths import get_windows_safe_path, enable_windows_long_paths

logger = setup_logging()


class OptimizedProgressTracker:
    """–¢—Ä–µ–∫–µ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
    
    def __init__(self, total_records: int):
        self.total_records = total_records
        self.processed = 0
        self.start_time = time.time()
        self.last_update_time = time.time()
        self.last_update_count = 0
        self.speeds = deque(maxlen=20)  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        self.batch_times = deque(maxlen=10)
        self.eta_history = deque(maxlen=3)
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
        self.memory_samples = deque(maxlen=100)
        self.max_memory_usage = 0
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        self.records_per_second = 0
        self.avg_batch_size = 0
        
    def update(self, processed: int, batch_size: int = 0, memory_usage_mb: float = 0):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º –ø–∞–º—è—Ç–∏"""
        self.processed = processed
        
        current_time = time.time()
        time_since_last = current_time - self.last_update_time
        records_since_last = processed - self.last_update_count
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∫–æ—Ä–æ—Å—Ç–∏
        if time_since_last >= 0.5 and records_since_last > 0:  # –†–∞–∑ –≤ 0.5 —Å–µ–∫—É–Ω–¥—ã
            speed = records_since_last / time_since_last
            self.speeds.append(speed)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω—é—é —Å–∫–æ—Ä–æ—Å—Ç—å
            if self.speeds:
                self.records_per_second = sum(self.speeds) / len(self.speeds)
            
            self.last_update_time = current_time
            self.last_update_count = processed
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞—Ç—á–µ–π
        if batch_size > 0:
            self.batch_times.append((batch_size, time_since_last))
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            if self.batch_times:
                self.avg_batch_size = sum(b[0] for b in self.batch_times) / len(self.batch_times)
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
        if memory_usage_mb > 0:
            self.memory_samples.append(memory_usage_mb)
            self.max_memory_usage = max(self.max_memory_usage, memory_usage_mb)
    
    def get_progress_string(self, metrics: ProcessingMetrics) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–æ–∫—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
        if self.total_records == 0:
            return "–û–∂–∏–¥–∞–Ω–∏–µ..."
        
        progress_percent = (self.processed / self.total_records) * 100
        
        # –í—Ä–µ–º—è
        elapsed = time.time() - self.start_time
        hours = int(elapsed // 3600)
        minutes = int((elapsed % 3600) // 60)
        seconds = int(elapsed % 60)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º ETA
        eta_seconds = 0
        if self.records_per_second > 0:
            remaining = self.total_records - self.processed
            eta_seconds = remaining / self.records_per_second
            
            # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ ETA
            self.eta_history.append(eta_seconds)
            if self.eta_history:
                avg_eta = sum(self.eta_history) / len(self.eta_history)
                eta_seconds = avg_eta
            
            eta_hours = int(eta_seconds // 3600)
            eta_minutes = int((eta_seconds % 3600) // 60)
            eta_seconds = int(eta_seconds % 60)
            eta_str = f"{eta_hours:02d}:{eta_minutes:02d}:{eta_seconds:02d}"
        else:
            eta_str = "??:??:??"
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        try:
            memory_usage = psutil.virtual_memory().percent
            # –°—Ç–∞—Ç—É—Å –ø–∞–º—è—Ç–∏
            if memory_usage < 60:
                memory_status = "üü¢"
            elif memory_usage < 80:
                memory_status = "üü°"
            else:
                memory_status = "üî¥"
        except:
            memory_usage = 0
            memory_status = "‚ö™"
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
        lines = [
            f"üìä {progress_percent:6.2f}% | üìà {self.processed:,}/{self.total_records:,}",
            f"‚ö° {self.records_per_second:.0f}/—Å–µ–∫ | ‚è±Ô∏è {hours:02d}:{minutes:02d}:{seconds:02d}",
            f"‚è≥ ETA: {eta_str} | üß† {memory_status} {memory_usage:5.1f}%",
            f"üñºÔ∏è {metrics.valid_images:,}‚úÖ {metrics.failed_images:,}‚ùå | üíæ {self.max_memory_usage/1024:.1f}GB"
        ]
        
        return " | ".join(lines)
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç—Ä–µ–∫–µ—Ä–∞"""
        if self.memory_samples:
            avg_memory = sum(self.memory_samples) / len(self.memory_samples)
        else:
            avg_memory = 0
        
        return {
            'processed': self.processed,
            'total': self.total_records,
            'progress_percent': (self.processed / self.total_records * 100) if self.total_records > 0 else 0,
            'records_per_second': self.records_per_second,
            'avg_batch_size': self.avg_batch_size,
            'elapsed_time': time.time() - self.start_time,
            'max_memory_usage_mb': self.max_memory_usage,
            'avg_memory_usage_mb': avg_memory
        }


class BatchProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –±–∞—Ç—á–µ–π —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, image_processor: ImageProcessorWithEmbedding, metrics: ProcessingMetrics):
        self.image_processor = image_processor
        self.metrics = metrics
        self.batch_results = []
        self.last_memory_check = time.time()
        self.memory_lock = asyncio.Lock()  # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –ø–∞–º—è—Ç–∏
        
    async def process_batch_optimized(self, batch_data: List[Tuple[str, str]], 
                                    current_position: int) -> List[FaceRecord]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∑–∞–ø–∏—Å–µ–π"""
        if not batch_data:
            return []
        
        batch_start_time = time.time()
        batch_size = len(batch_data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        await self._check_memory_and_adjust()
        
        try:
            # –®–∞–≥ 1: –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –≤ –±–∞—Ç—á–µ
            lines = [line for line, _ in batch_data]
            parsed_records = parse_batch_records(lines, self.metrics)
            
            if not parsed_records:
                return []
            
            # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            image_urls = []
            record_indices = []
            
            for i, record_data in enumerate(parsed_records):
                if record_data and record_data.get('image_url'):
                    image_urls.append(record_data['image_url'])
                    record_indices.append(i)
            
            # –®–∞–≥ 3: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            image_results = []
            if image_urls:
                try:
                    image_results = await process_images_batch(
                        self.image_processor, 
                        image_urls, 
                        self.metrics
                    )
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–∞—Ç—á–∞: {e}")
                    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏
                    image_results = [None] * len(image_urls)
            
            # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ FaceRecord
            face_records = []
            image_result_idx = 0
            
            for i, record_data in enumerate(parsed_records):
                if not record_data:
                    continue
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∑–∞–ø–∏—Å–∏
                try:
                    record = FaceRecord(**record_data)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    if i in record_indices and image_result_idx < len(image_results):
                        img_result = image_results[image_result_idx]
                        image_result_idx += 1
                        
                        if img_result and hasattr(img_result, '_fields'):  # NamedTuple –ø—Ä–æ–≤–µ—Ä–∫–∞
                            filepath, base64_str, img_info = img_result
                            
                            if filepath and base64_str:
                                record.image_path = filepath
                                record.image_base64 = base64_str
                                if img_info:
                                    record.image_width = img_info.get('width', 0)
                                    record.image_height = img_info.get('height', 0)
                                    record.image_size_kb = img_info.get('file_size_kb', 0)
                                    record.download_time_ms = img_info.get('download_time_ms', 0)
                                    record.is_cached = img_info.get('is_cached', False)
                                record.image_hash = hashlib.md5(record.image_url.encode()).hexdigest()
                            elif record.image_url:
                                record.failed_reason = img_info.get('failed_reason', '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏') if img_info else '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏'
                                record.image_hash = hashlib.md5(record.image_url.encode()).hexdigest()
                    
                    face_records.append(record)
                    
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è FaceRecord: {e}")
                    continue
            
            # –®–∞–≥ 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            batch_time = time.time() - batch_start_time
            self.metrics.add_batch_time(batch_time)
            
            # –®–∞–≥ 6: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö IP
            for record in face_records:
                if record.ip_address and record.ip_address != '–ù/–î':
                    self.metrics.unique_ips.add(record.ip_address)
            
            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á –∏–∑ {batch_size} –∑–∞–ø–∏—Å–µ–π –∑–∞ {batch_time:.2f} —Å–µ–∫")
            return face_records
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞: {e}", exc_info=True)
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._create_fallback_records(batch_data)
    
    async def _check_memory_and_adjust(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–º—è—Ç—å –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"""
        async with self.memory_lock:
            current_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —á–∞—â–µ —á–µ–º —Ä–∞–∑ –≤ 2 —Å–µ–∫—É–Ω–¥—ã
            if current_time - self.last_memory_check < 2:
                return
            
            self.last_memory_check = current_time
            
            try:
                memory_percent = psutil.virtual_memory().percent
                available_gb = psutil.virtual_memory().available / (1024**3)
                
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
                if memory_percent > 90 or available_gb < 0.2:
                    logger.warning(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_percent:.1f}%, {available_gb:.2f}GB —Å–≤–æ–±–æ–¥–Ω–æ")
                    await asyncio.sleep(5)
                    gc.collect()
                elif memory_percent > 80 or available_gb < 0.5:
                    logger.debug(f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_percent:.1f}%")
                    await asyncio.sleep(1)
                    gc.collect()
                elif memory_percent > 70:
                    await asyncio.sleep(0.5)
                    
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    def _create_fallback_records(self, batch_data: List[Tuple[str, str]]) -> List[FaceRecord]:
        """–°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        records = []
        parser = get_global_parser()
        
        for line, line_hash in batch_data:
            try:
                record_data = parser.parse_record(line, self.metrics)
                if record_data:
                    record = FaceRecord(**record_data)
                    records.append(record)
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è fallback –∑–∞–ø–∏—Å–∏: {e}")
                continue
        
        return records


class OptimizedMemoryManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º"""
    
    def __init__(self):
        self.peak_memory = 0
        self.memory_samples = deque(maxlen=1000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏
        self.last_cleanup = time.time()
        self.cleanup_lock = threading.Lock()
        
    def check_memory_safe(self, additional_mb: float = 0) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±–µ–∑–æ–ø–∞—Å–Ω–æ –ª–∏ –≤—ã–¥–µ–ª—è—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–∞–º—è—Ç—å"""
        try:
            memory = psutil.virtual_memory()
            current_usage = memory.percent
            available_mb = memory.available / (1024**2)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∏–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            self.peak_memory = max(self.peak_memory, memory.used / (1024**3))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ç–º–ø–ª
            with self.cleanup_lock:
                self.memory_samples.append({
                    'time': time.time(),
                    'percent': current_usage,
                    'available_mb': available_mb,
                    'used_gb': memory.used / (1024**3)
                })
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            safe_percent = current_usage < Config.MAX_MEMORY_PERCENT
            safe_available = (available_mb - additional_mb) > 200  # –ú–∏–Ω–∏–º—É–º 200MB —Å–≤–æ–±–æ–¥–Ω–æ
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not safe_percent or not safe_available:
                if time.time() - self.last_cleanup > 30:
                    self.force_cleanup()
            
            return safe_percent and safe_available
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
            return True
    
    def force_cleanup(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏"""
        with self.cleanup_lock:
            self.last_cleanup = time.time()
            
            try:
                # –û—á–∏—â–∞–µ–º –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞
                parser = get_global_parser()
                if hasattr(parser, 'clear_cache'):
                    parser.clear_cache()
                
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
                for _ in range(2):  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤
                    gc.collect()
                
                logger.info("–í—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏")
                
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        if not self.memory_samples:
            return {
                'peak_memory_gb': 0,
                'avg_memory_percent': 0,
                'current_memory_percent': 0,
                'samples_count': 0
            }
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        with self.cleanup_lock:
            samples = list(self.memory_samples)  # –ö–æ–ø–∏—Ä—É–µ–º –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        
        if not samples:
            return {
                'peak_memory_gb': self.peak_memory,
                'avg_memory_percent': 0,
                'current_memory_percent': 0,
                'samples_count': 0
            }
        
        avg_percent = sum(s['percent'] for s in samples) / len(samples)
        current_percent = samples[-1]['percent'] if samples else 0
        
        return {
            'peak_memory_gb': self.peak_memory,
            'avg_memory_percent': avg_percent,
            'current_memory_percent': current_percent,
            'samples_count': len(samples),
            'last_cleanup': self.last_cleanup
        }


class FaceRecognitionProcessor:
    """–ì–ª–∞–≤–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, formats: List[str], resume: bool = False):
        self.metrics = ProcessingMetrics()
        self.records: List[FaceRecord] = []
        self.image_processor = None
        self.formats = formats
        self.output_dir = ""
        self.report_generator = None
        self.checkpoint_manager = None
        self.resume = resume
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.batch_size = Config.INITIAL_BATCH_SIZE
        self.max_batch_size = 20000
        self.min_batch_size = 500
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.memory_manager = OptimizedMemoryManager()
        self.memory_monitor = MemoryMonitor()
        self.batch_processor = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processed_hashes: Set[str] = set()
        self.last_checkpoint_save = 0
        self.processed_since_checkpoint = 0
        self.progress_tracker = None
        self.is_running = True
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_batches_processed = 0
        self.avg_batch_processing_time = 0
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.performance_stats = {
            'file_read_speed': 0,
            'parsing_speed': 0,
            'image_processing_speed': 0,
            'total_records_processed': 0
        }
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è Windows
        self._setup_signal_handlers()
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω FaceRecognitionProcessor —Å batch_size={self.batch_size}")
    
    def _setup_signal_handlers(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
        if platform.system() == "Windows":
            try:
                # –î–ª—è Windows –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
                import win32api
                
                def windows_signal_handler(signal_type):
                    if signal_type in [2, 15]:  # CTRL_C_EVENT, CTRL_BREAK_EVENT
                        print("\n‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è, –∑–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                        self.is_running = False
                        return True  # –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ
                    return False
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
                win32api.SetConsoleCtrlHandler(windows_signal_handler, True)
            except ImportError:
                logger.warning("–ú–æ–¥—É–ª—å win32api –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            # –î–ª—è Unix-—Å–∏—Å—Ç–µ–º
            import signal
            
            def unix_signal_handler(signum, frame):
                print(f"\n‚ö†Ô∏è  –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª {signum}, –∑–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                self.is_running = False
            
            signal.signal(signal.SIGINT, unix_signal_handler)
            signal.signal(signal.SIGTERM, unix_signal_handler)
    
    async def process_file(self, input_file: str) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        logger.info(f"üéØ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {os.path.basename(input_file)}")
        
        # –í–∫–ª—é—á–∞–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –¥–ª–∏–Ω–Ω—ã—Ö –ø—É—Ç–µ–π –¥–ª—è Windows
        if platform.system() == "Windows":
            enable_windows_long_paths()
        
        # –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–∞–º—è—Ç–∏
        self.memory_monitor.start()
        
        # –ù–∞—á–∞–ª–æ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–∞–º—è—Ç–∏
        tracemalloc.start()
        
        try:
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫
            print("üîç –ü–æ–¥—Å—á–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ...")
            total_lines = await self._count_lines_optimized(input_file)
            if total_lines == 0:
                logger.error("–§–∞–π–ª –ø—É—Å—Ç")
                return False
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_lines:,}")
            print(f"üìÅ –§–æ—Ä–º–∞—Ç—ã –æ—Ç—á–µ—Ç–æ–≤: {', '.join(self.formats)}")
            
            system_info = Config.get_system_info()
            print(f"üíæ –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞–º—è—Ç–∏: {system_info['memory_available_gb']:.1f} GB")
            print(f"üíø –°–≤–æ–±–æ–¥–Ω–æ –Ω–∞ –¥–∏—Å–∫–µ: {system_info['disk_free_gb']:.1f} GB")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
            self.output_dir = Config.setup_directories()
            print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.output_dir}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
            self.checkpoint_manager = CheckpointManager(self.output_dir)
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            start_position, checkpoint_data = await self._load_checkpoint_state(input_file, total_lines)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            self.progress_tracker = OptimizedProgressTracker(total_lines)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            self.image_processor = ImageProcessorWithEmbedding(self.output_dir)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞—Ç—á-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
            self.batch_processor = BatchProcessor(self.image_processor, self.metrics)
            
            print("\n" + "="*80)
            print("üöÄ –ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò")
            print("="*80)
            
            # –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            processing_task = asyncio.create_task(
                self._process_file_optimized(input_file, total_lines, start_position)
            )
            
            # –ó–∞–ø—É—Å–∫ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            progress_task = asyncio.create_task(self._display_optimized_progress())
            
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            monitor_task = asyncio.create_task(self._monitor_performance())
            
            # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º wait —Å —Ç–∞–π–º–∞—É—Ç–æ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–π
                done, pending = await asyncio.wait(
                    [processing_task],
                    timeout=3600 * 24,  # 24 —á–∞—Å–∞ –º–∞–∫—Å–∏–º—É–º
                    return_when=asyncio.FIRST_COMPLETED
                )
                
                if processing_task in done:
                    success = processing_task.result()
                else:
                    # –¢–∞–π–º–∞—É—Ç –∏–ª–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ
                    processing_task.cancel()
                    try:
                        await processing_task
                    except asyncio.CancelledError:
                        pass
                    success = False
                    print("\n‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ —Ç–∞–π–º–∞—É—Ç—É")
                
            except KeyboardInterrupt:
                print("\n\n‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                self.is_running = False
                success = False
            finally:
                # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á
                progress_task.cancel()
                monitor_task.cancel()
                try:
                    await asyncio.wait_for(progress_task, timeout=2.0)
                    await asyncio.wait_for(monitor_task, timeout=2.0)
                except (asyncio.TimeoutError, asyncio.CancelledError):
                    pass
            
            if success:
                # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
                current_position = await self._get_file_position_async(input_file, start_position, self.metrics.total_records)
                self._save_checkpoint(input_file, total_lines, current_position)
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
                await self._generate_reports()
                
                return True
            else:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                if self.metrics.total_records > 0:
                    current_position = await self._get_file_position_async(input_file, start_position, self.metrics.total_records)
                    self._save_checkpoint(input_file, total_lines, current_position)
                    print("üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è")
                return False
            
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", exc_info=True)
            traceback.print_exc()
            return False
        finally:
            self.is_running = False
            self.memory_monitor.stop()
            
            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–∞–º—è—Ç–∏
            if tracemalloc.is_tracing():
                try:
                    snapshot = tracemalloc.take_snapshot()
                    top_stats = snapshot.statistics('lineno')[:10]
                    
                    logger.info("–¢–æ–ø-10 —Å—Ç—Ä–æ–∫ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞–º—è—Ç–∏:")
                    for stat in top_stats:
                        logger.info(f"{stat}")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–µ –ø–∞–º—è—Ç–∏: {e}")
                
                tracemalloc.stop()
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
            await self._final_cleanup()
    
    async def _load_checkpoint_state(self, input_file: str, total_lines: int) -> Tuple[int, Optional[Dict]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        start_position = 0
        
        if self.resume:
            checkpoint = self.checkpoint_manager.load_checkpoint()
            if checkpoint and self.checkpoint_manager.validate_checkpoint(input_file)[0]:
                start_position = checkpoint.last_position
                total_lines = checkpoint.total_lines
                self.metrics.total_records = checkpoint.processed_lines
                self.metrics.valid_images = checkpoint.valid_images
                self.metrics.failed_images = checkpoint.failed_images
                self.metrics.json_errors = checkpoint.json_errors
                self.metrics.cached_images = checkpoint.cached_images
                self.metrics.network_errors = checkpoint.network_errors
                self.metrics.timeout_errors = checkpoint.timeout_errors
                self.metrics.duplicate_records = checkpoint.duplicate_records
                self.batch_size = checkpoint.batch_size
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö—ç—à–∏ –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                self.processed_hashes = set(checkpoint.records_processed)
                self.metrics.unique_users = set(checkpoint.unique_users)
                self.metrics.unique_devices = set(checkpoint.unique_devices)
                self.metrics.unique_companies = set(checkpoint.unique_companies)
                self.metrics.unique_ips = set(checkpoint.unique_ips)
                
                print(f"üîÑ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø–æ–∑–∏—Ü–∏–∏: {start_position:,} –±–∞–π—Ç")
                print(f"üîÑ –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {checkpoint.processed_lines:,} –∑–∞–ø–∏—Å–µ–π")
                print(f"üîÑ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size:,}")
                
                return start_position, checkpoint
            else:
                if checkpoint:
                    print("‚ö†Ô∏è  –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ–≤–∞–ª–∏–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞")
                else:
                    print("üîÑ –ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, –Ω–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞—á–∞–ª–∞")
                self.checkpoint_manager.clear_checkpoint()
        
        return start_position, None
    
    async def _process_file_optimized(self, input_file: str, total_lines: int, start_position: int) -> bool:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
        try:
            async with self.image_processor:
                # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –û–°
                if platform.system() == "Windows":
                    buffer_size = 1024 * 1024 * 2  # 2MB –¥–ª—è Windows
                else:
                    buffer_size = 1024 * 1024 * 10  # 10MB –¥–ª—è –¥—Ä—É–≥–∏—Ö –û–°
                
                with open(input_file, 'r', encoding='utf-8', buffering=buffer_size, errors='ignore') as f:
                    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º—Å—è –∫ –ø–æ–∑–∏—Ü–∏–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    if start_position > 0:
                        f.seek(start_position)
                    
                    batch_data = []
                    batch_count = 0
                    lines_processed = 0
                    current_byte_position = start_position
                    
                    batch_start_time = time.time()
                    
                    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º
                    for line in f:
                        if not self.is_running:
                            break
                        
                        line = line.strip()
                        if not line:
                            continue
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ —Ñ–∞–π–ª–µ
                        current_byte_position += len(line.encode('utf-8', errors='replace')) + 1  # +1 –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
                        
                        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö—ç—à —Å—Ç—Ä–æ–∫–∏
                        line_hash = hashlib.md5(line.encode('utf-8', errors='replace')).hexdigest()[:16]
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç
                        if line_hash in self.processed_hashes:
                            self.metrics.total_records += 1
                            self.metrics.duplicate_records += 1
                            continue
                        
                        batch_data.append((line, line_hash))
                        lines_processed += 1
                        self.processed_hashes.add(line_hash)
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á –∫–æ–≥–¥–∞ –Ω–∞–∫–æ–ø–∏—Ç—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
                        if len(batch_data) >= self.batch_size:
                            await self._process_and_update_batch(batch_data, current_byte_position, batch_count, input_file, total_lines)
                            
                            batch_data = []
                            batch_count += 1
                            
                            # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
                            self._adjust_batch_size_dynamically(batch_count)
                            
                            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –±–∞—Ç—á–∞
                            batch_time = time.time() - batch_start_time
                            self.avg_batch_processing_time = (
                                self.avg_batch_processing_time * 0.9 + batch_time * 0.1
                            )
                            batch_start_time = time.time()
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞—Ç–∫–∞
                    if batch_data:
                        await self._process_and_update_batch(batch_data, current_byte_position, batch_count, input_file, total_lines)
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            traceback.print_exc()
            return False
    
    async def _process_and_update_batch(self, batch_data: List[Tuple[str, str]], 
                                      current_position: int, batch_count: int,
                                      input_file: str, total_lines: int):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞
        batch_records = await self.batch_processor.process_batch_optimized(
            batch_data, current_position
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
        self.records.extend(batch_records)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—á–µ—Ç—á–∏–∫–æ–≤
        processed_in_batch = len(batch_data)
        self.metrics.total_records += processed_in_batch
        self.metrics.processed_records += len(batch_records)
        self.total_batches_processed += 1
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (—Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 1000 –∑–∞–ø–∏—Å–µ–π –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –æ–≤–µ—Ä—Ö–µ–¥–∞)
        if self.metrics.total_records % 1000 == 0:
            memory_usage_mb = 0
            try:
                memory_usage_mb = psutil.virtual_memory().used / (1024**2)
            except:
                pass
            
            self.progress_tracker.update(
                self.metrics.total_records, 
                processed_in_batch,
                memory_usage_mb
            )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        self.processed_since_checkpoint += processed_in_batch
        if self.processed_since_checkpoint >= Config.CHECKPOINT_INTERVAL:
            self._save_checkpoint(
                os.path.basename(input_file),
                total_lines,
                current_position
            )
            self.processed_since_checkpoint = 0
            
            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π
            await self._save_records_intermediate()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –∫–∞–∂–¥—ã–µ 10 –±–∞—Ç—á–µ–π
        if batch_count % 10 == 0:
            await self._optimize_memory_usage()
    
    async def _optimize_memory_usage(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–∞—Ä—Å–µ—Ä–∞ –µ—Å–ª–∏ –æ–Ω —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π
            parser = get_global_parser()
            if parser and hasattr(parser, '_cache'):
                cache_size = len(parser._cache) if hasattr(parser._cache, '__len__') else 0
                if cache_size > 15000:
                    parser.clear_cache()
                    logger.debug(f"–û—á–∏—â–µ–Ω –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞ (–±—ã–ª–æ {cache_size} –∑–∞–ø–∏—Å–µ–π)")
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
            collected = gc.collect()
            logger.debug(f"–°–æ–±—Ä–∞–Ω–æ –º—É—Å–æ—Ä–∞: {collected} –æ–±—ä–µ–∫—Ç–æ–≤")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            try:
                memory_percent = psutil.virtual_memory().percent
                if memory_percent > 85:
                    logger.warning(f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ ({memory_percent}%), –ø–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥—ã")
                    await asyncio.sleep(2)
            except:
                pass
                
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    async def _save_records_intermediate(self):
        """–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        if len(self.records) < 10000:
            return
        
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç—å –∑–∞–ø–∏—Å–µ–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            save_count = len(self.records) // 2
            records_to_save = self.records[:save_count]
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø—É—Ç—å –¥–ª—è Windows
            temp_dir = get_windows_safe_path(self.output_dir, Config.TEMP_FOLDER)
            os.makedirs(temp_dir, exist_ok=True)
            
            temp_file = get_windows_safe_path(
                temp_dir, 
                f"records_temp_{int(time.time())}.jsonl"
            )
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é
            with open(temp_file, 'w', encoding='utf-8', errors='ignore') as f:
                for record in records_to_save:
                    try:
                        record_dict = record.to_dict()
                        f.write(json.dumps(record_dict, ensure_ascii=False) + '\n')
                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∏: {e}")
                        continue
            
            # –£–¥–∞–ª—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –ø–∞–º—è—Ç–∏
            del self.records[:save_count]
            
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {save_count} –∑–∞–ø–∏—Å–µ–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª")
            
            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏
            gc.collect()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–µ–π: {e}")
    
    async def _load_saved_records(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_dir = get_windows_safe_path(self.output_dir, Config.TEMP_FOLDER)
        if not os.path.exists(temp_dir):
            return
        
        try:
            temp_files = []
            for filename in os.listdir(temp_dir):
                if filename.startswith('records_temp_') and filename.endswith('.jsonl'):
                    filepath = os.path.join(temp_dir, filename)
                    temp_files.append((os.path.getmtime(filepath), filepath))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            temp_files.sort()
            
            loaded_count = 0
            for _, filepath in temp_files:
                try:
                    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                        for line in f:
                            if line.strip():
                                try:
                                    data = json.loads(line.strip())
                                    record = FaceRecord(**data)
                                    self.records.append(record)
                                    loaded_count += 1
                                except json.JSONDecodeError as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                                    continue
                    
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    os.remove(filepath)
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {filepath}: {e}")
            
            if loaded_count > 0:
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {e}")
    
    def _adjust_batch_size_dynamically(self, batch_count: int):
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            memory_percent = psutil.virtual_memory().percent
            available_gb = psutil.virtual_memory().available / (1024**3)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ü–µ–ª–µ–≤—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
            target_records_per_second = 1000  # –¶–µ–ª–µ–≤–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å
            
            # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            if memory_percent > 85 or available_gb < 0.5:
                # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è —Å–∏—Ç—É–∞—Ü–∏—è - —Ä–µ–∑–∫–æ —É–º–µ–Ω—å—à–∞–µ–º
                new_size = max(self.min_batch_size, self.batch_size // 2)
                if new_size != self.batch_size:
                    logger.warning(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø–∞–º—è—Ç—å: —É–º–µ–Ω—å—à–∞–µ–º batch_size –¥–æ {new_size}")
            elif memory_percent > 75:
                # –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ - –Ω–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∞–µ–º
                new_size = max(self.min_batch_size, int(self.batch_size * 0.7))
                if new_size != self.batch_size and batch_count % 5 == 0:
                    logger.info(f"–í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –ø–∞–º—è—Ç–∏: —É–º–µ–Ω—å—à–∞–µ–º batch_size –¥–æ {new_size}")
            elif self.avg_batch_processing_time > 10:
                # –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ - —É–º–µ–Ω—å—à–∞–µ–º
                new_size = max(self.min_batch_size, int(self.batch_size * 0.8))
                if new_size != self.batch_size:
                    logger.info(f"–ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —É–º–µ–Ω—å—à–∞–µ–º batch_size –¥–æ {new_size}")
            elif (memory_percent < 60 and available_gb > 2 and 
                  self.avg_batch_processing_time < 5 and 
                  self.batch_size < self.max_batch_size):
                # –•–æ—Ä–æ—à–∏–µ —É—Å–ª–æ–≤–∏—è - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
                new_size = min(self.max_batch_size, int(self.batch_size * 1.5))
                if new_size != self.batch_size and batch_count % 10 == 0:
                    logger.info(f"–•–æ—Ä–æ—à–∏–µ —É—Å–ª–æ–≤–∏—è: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º batch_size –¥–æ {new_size}")
            else:
                new_size = self.batch_size
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä
            self.batch_size = new_size
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞: {e}")
    
    async def _display_optimized_progress(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        last_update = 0
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –æ–≤–µ—Ä—Ö–µ–¥–∞
                if current_time - last_update >= 2.0 and self.progress_tracker:
                    # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å (–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ)
                    
                    # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    progress_str = self.progress_tracker.get_progress_string(self.metrics)
                    sys.stdout.write('\r' + progress_str + ' ' * 10)
                    sys.stdout.flush()
                    
                    last_update = current_time
                
                await asyncio.sleep(0.5)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                await asyncio.sleep(1)
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        if self.progress_tracker:
            try:
                progress_str = self.progress_tracker.get_progress_string(self.metrics)
                sys.stdout.write('\r' + progress_str + ' ' * 10 + '\n')
                sys.stdout.flush()
            except:
                pass
    
    async def _monitor_performance(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        last_check = time.time()
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                if current_time - last_check >= 5:
                    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞—Ä—Å–µ—Ä–∞
                    parser = get_global_parser()
                    parser_stats = parser.get_statistics() if hasattr(parser, 'get_statistics') else {}
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if self.progress_tracker:
                        self.performance_stats['records_per_second'] = (
                            self.progress_tracker.records_per_second
                        )
                    
                    self.performance_stats['total_records_processed'] = self.metrics.total_records
                    self.performance_stats['parser_cache_hit_rate'] = parser_stats.get('cache_hit_rate', 'N/A')
                    
                    last_check = current_time
                
                await asyncio.sleep(1)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {e}")
                await asyncio.sleep(5)
    
    def _save_checkpoint(self, input_file: str, total_lines: int, position: int):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç"""
        if self.checkpoint_manager:
            self.checkpoint_manager.save_checkpoint(
                file_name=os.path.basename(input_file),
                total_lines=total_lines,
                processed_lines=self.metrics.total_records,
                valid_images=self.metrics.valid_images,
                failed_images=self.metrics.failed_images,
                json_errors=self.metrics.json_errors,
                cached_images=self.metrics.cached_images,
                network_errors=self.metrics.network_errors,
                timeout_errors=self.metrics.timeout_errors,
                duplicate_records=self.metrics.duplicate_records,
                last_position=position,
                batch_size=self.batch_size,
                records_processed=list(self.processed_hashes),
                unique_users=list(self.metrics.unique_users),
                unique_devices=list(self.metrics.unique_devices),
                unique_companies=list(self.metrics.unique_companies),
                unique_ips=list(self.metrics.unique_ips)
            )
    
    async def _generate_reports(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤"""
        logger.info("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        await self._load_saved_records()
        
        print("\n" + "="*80)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print("="*80)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = StatisticsAnalyzer.analyze(self.records)
        
        print(f"‚úÖ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.metrics.total_records:,}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.valid_images:,}")
        print(f"‚ö†Ô∏è  –ù–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫: {self.metrics.failed_images:,}")
        print(f"‚ùå –û—à–∏–±–æ–∫ JSON: {self.metrics.json_errors:,}")
        print(f"üíæ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.cached_images:,}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.metrics.elapsed_time:.1f} —Å–µ–∫")
        if self.metrics.elapsed_time > 0:
            print(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {self.metrics.total_records / self.metrics.elapsed_time:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        print("‚îÄ" * 80)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"üè¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {len(self.metrics.unique_companies)}")
        print(f"üë§ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(self.metrics.unique_users)}")
        print(f"üì± –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {len(self.metrics.unique_devices)}")
        print(f"üåê –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö IP: {len(self.metrics.unique_ips)}")
        print(f"üì∏ –ó–∞–ø–∏—Å–µ–π —Å —Ñ–æ—Ç–æ: {stats['with_images']:,}")
        print(f"üéØ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–π (—Ç–∏–ø 1): {stats['by_event_type'].get('1', 0):,}")
        print(f"üìÖ –°–æ–±—ã—Ç–∏–π (—Ç–∏–ø 2): {stats['by_event_type'].get('2', 0):,}")
        print("‚îÄ" * 80)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        memory_stats = self.memory_monitor.get_statistics()
        print(f"üß† –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_stats['peak_memory_mb']:.1f} MB")
        print(f"üíæ –°—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_stats['avg_memory_mb']:.1f} MB")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
        parser = get_global_parser()
        if hasattr(parser, 'get_statistics'):
            parser_stats = parser.get_statistics()
            print(f"üìä –ö—ç—à –ø–∞—Ä—Å–µ—Ä–∞: {parser_stats.get('cache_hit_rate', 'N/A')}")
        
        print("="*80)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        reports_created = []
        
        if "HTML" in self.formats:
            print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–ª–æ–∂–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
            from src.processing.report_generator import ReportGenerator
            report_generator = ReportGenerator(self.output_dir)
            html_report = report_generator.generate_html_report(self.records, self.metrics)
            reports_created.append(("üåê HTML –æ—Ç—á–µ—Ç", html_report))
            print("‚úÖ HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ README —Ñ–∞–π–ª–∞
        self._create_readme(reports_created)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüéâ –û–¢–ß–ï–¢–´ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–´")
        print("="*80)
        print(f"üìÅ –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {self.output_dir}")
        
        for report_name, report_path in reports_created:
            if report_path:
                print(f"   ‚Ä¢ {report_name}: {os.path.basename(report_path)}")
        
        print(f"üñºÔ∏è  –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.join(self.output_dir, Config.IMAGE_FOLDER)}")
        print("="*80)
    
    def _create_readme(self, reports_created: List[Tuple[str, str]]):
        """–°–æ–∑–¥–∞–Ω–∏–µ README —Ñ–∞–π–ª–∞"""
        memory_stats = self.memory_monitor.get_statistics()
        
        readme_content = f"""
# –û–¢–ß–ï–¢ –ü–û –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Æ –õ–ò–¶

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.datetime.now().strftime("%d.%m.%Y %H:%M:%S")}
- –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {self.metrics.total_records:,}
- –£—Å–ø–µ—à–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.valid_images:,}
- –û—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏: {self.metrics.failed_images:,}
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.metrics.elapsed_time:.1f} —Å–µ–∫
- –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {self.metrics.total_records / self.metrics.elapsed_time:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫
- –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_stats['peak_memory_mb']:.1f} MB

## üöÄ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:
‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–æ–ª–µ–µ 2 –ì–ë
‚úÖ –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ (–¥–æ 85% –û–ó–£)
‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∫–∞–∂–¥—ã–µ 100,000 –∑–∞–ø–∏—Å–µ–π
‚úÖ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
‚úÖ –û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–µ—Ç–∏ –∏ –ø–∞–º—è—Ç–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

## üìÑ –°–æ–∑–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã:
"""
        
        for report_name, report_path in reports_created:
            if report_path:
                readme_content += f"- {report_name}: {os.path.basename(report_path)}\n"
        
        readme_content += f"""
## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫
{self.output_dir}/
‚îú‚îÄ‚îÄ {Config.IMAGE_FOLDER}/     # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ {Config.CACHE_FOLDER}/     # –ö—ç—à –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚îú‚îÄ‚îÄ {Config.TEMP_FOLDER}/      # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
‚îî‚îÄ‚îÄ {Config.REPORTS_FOLDER}/   # –í—Å–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç—ã

## üîß –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
1. –û—Ç–∫—Ä–æ–π—Ç–µ HTML –æ—Ç—á–µ—Ç –≤ –±—Ä–∞—É–∑–µ—Ä–µ
2. –í—Å–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —É–∂–µ –≤—Å—Ç—Ä–æ–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏/—Ç–∏–ø—É
4. –ù–∞–∂–∏–º–∞–π—Ç–µ –Ω–∞ —Ñ–æ—Ç–æ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è
5. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ

## ‚ö†Ô∏è –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
–ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–ª–∞—Å—å, –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≥—Ä–∞–º–º—É —Å –∫–ª—é—á–æ–º --resume
–ü—Ä–æ–≥—Ä–∞–º–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞.

## üí° –°–æ–≤–µ—Ç—ã
- –î–ª—è —Ñ–∞–π–ª–æ–≤ >1 –ì–ë —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ HTML –æ—Ç—á–µ—Ç
- SSD —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É —Å –∫—ç—à–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- –ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å –ø–∞–º—è—Ç—å—é –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–º–µ–Ω—å—à–∏—Ç batch_size
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–ª—è –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
"""
        
        readme_path = os.path.join(self.output_dir, "README.txt")
        try:
            with open(readme_path, 'w', encoding='utf-8', errors='ignore') as f:
                f.write(readme_content)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è README —Ñ–∞–π–ª–∞: {e}")
    
    async def _count_lines_optimized(self, file_path: str) -> int:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ"""
        loop = asyncio.get_event_loop()
        
        def count_lines_sync():
            count = 0
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞
            if platform.system() == "Windows":
                buffer_size = 1024 * 1024 * 4  # 4MB –¥–ª—è Windows
            else:
                buffer_size = 1024 * 1024 * 8  # 8MB –¥–ª—è –¥—Ä—É–≥–∏—Ö –û–°
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore', buffering=buffer_size) as f:
                while True:
                    buffer = f.read(buffer_size)
                    if not buffer:
                        break
                    count += buffer.count('\n')
            
            return count
        
        with ThreadPoolExecutor(max_workers=1) as executor:
            result = await loop.run_in_executor(executor, count_lines_sync)
        
        return result
    
    async def _get_file_position_async(self, file_path: str, start_position: int, processed_lines: int) -> int:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ñ–∞–π–ª–µ"""
        try:
            if processed_lines == 0:
                return start_position
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(file_path)
            
            # –ï—Å–ª–∏ –º—ã –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º start_position
            if start_position == 0:
                # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
                if processed_lines > 1000:
                    # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 1000 —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        total_bytes = 0
                        lines_read = 0
                        for _ in range(min(1000, processed_lines)):
                            line = f.readline()
                            if not line:
                                break
                            total_bytes += len(line.encode('utf-8', errors='replace'))
                            lines_read += 1
                        
                        if lines_read > 0:
                            avg_line_size = total_bytes / lines_read
                            estimated_position = int(start_position + (processed_lines * avg_line_size))
                            return min(estimated_position, file_size)
            
            return start_position
            
        except:
            return start_position
    
    async def _final_cleanup(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–∞—Ä—Å–µ—Ä–∞
            parser = get_global_parser()
            if hasattr(parser, 'clear_cache'):
                parser.clear_cache()
            
            # –û—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–æ–≤
            self.records.clear()
            self.processed_hashes.clear()
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
            for _ in range(2):  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏–∫–ª–æ–≤
                gc.collect()
            
            logger.info("–í—ã–ø–æ–ª–Ω–µ–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ: {e}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        memory_stats = self.memory_monitor.get_statistics()
        
        report = {
            'processing': {
                'total_records': self.metrics.total_records,
                'processing_time_seconds': self.metrics.elapsed_time,
                'records_per_second': self.metrics.total_records / self.metrics.elapsed_time if self.metrics.elapsed_time > 0 else 0,
                'success_rate': self.metrics.success_rate,
                'batches_processed': self.total_batches_processed,
                'avg_batch_processing_time': self.avg_batch_processing_time,
                'final_batch_size': self.batch_size
            },
            'memory': memory_stats,
            'images': {
                'valid': self.metrics.valid_images,
                'failed': self.metrics.failed_images,
                'cached': self.metrics.cached_images,
                'success_rate': self.metrics.success_rate
            },
            'uniques': {
                'users': len(self.metrics.unique_users),
                'devices': len(self.metrics.unique_devices),
                'companies': len(self.metrics.unique_companies),
                'ips': len(self.metrics.unique_ips)
            }
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–∞—Ä—Å–µ—Ä–∞
        parser = get_global_parser()
        if hasattr(parser, 'get_statistics'):
            report['parser'] = parser.get_statistics()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç—Ä–µ–∫–µ—Ä–∞
        if self.progress_tracker:
            report['progress_tracker'] = self.progress_tracker.get_statistics()
        
        return report