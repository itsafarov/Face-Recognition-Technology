"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –æ–≤–µ—Ä—Ö–µ–¥–æ–º
"""
import os
import sys
import gc
import hashlib
import datetime
import asyncio
import time
import traceback
import json
from typing import List, Tuple, Set, Dict, Any, Optional, Deque
from collections import deque
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor

import psutil
import tracemalloc

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ
from .config import Config
from .models import ProcessingMetrics, FaceRecord
from .data_parser import parse_batch_records, get_global_parser
from .checkpoint_manager import CheckpointManager
from processing.image_processor import ImageProcessorWithEmbedding, process_images_batch
from processing.report_generator import ReportGenerator
from src.utils.logger import setup_logger
from src.utils.memory_monitor import MemoryMonitor

logger = setup_logger()


@dataclass
class ProgressStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    total_records: int = 0
    processed_records: int = 0
    start_time: float = 0.0
    last_update_time: float = 0.0
    last_update_count: int = 0
    speeds: Deque[float] = None
    batch_times: Deque[Tuple[int, float]] = None
    memory_samples: Deque[float] = None
    eta_history: Deque[float] = None
    
    def __post_init__(self):
        if self.speeds is None:
            self.speeds = deque(maxlen=10)
        if self.batch_times is None:
            self.batch_times = deque(maxlen=5)
        if self.memory_samples is None:
            self.memory_samples = deque(maxlen=20)
        if self.eta_history is None:
            self.eta_history = deque(maxlen=3)
        if self.start_time == 0:
            self.start_time = time.time()
        self.last_update_time = self.start_time
        self.last_update_count = 0
    
    def update(self, processed: int, batch_size: int = 0, memory_usage_mb: float = 0):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        self.processed_records = processed
        
        current_time = time.time()
        time_since_last = current_time - self.last_update_time
        records_since_last = processed - self.last_update_count
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å–∫–æ—Ä–æ—Å—Ç–∏
        if time_since_last >= 5.0 and records_since_last > 0:
            speed = records_since_last / time_since_last
            self.speeds.append(speed)
            self.last_update_time = current_time
            self.last_update_count = processed
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞—Ç—á–µ–π
        if batch_size > 0:
            self.batch_times.append((batch_size, time_since_last))
        
        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏
        if memory_usage_mb > 0:
            self.memory_samples.append(memory_usage_mb)
    
    @property
    def progress_percent(self) -> float:
        if self.total_records == 0:
            return 0.0
        return (self.processed_records / self.total_records) * 100
    
    @property
    def records_per_second(self) -> float:
        if not self.speeds:
            return 0.0
        return sum(self.speeds) / len(self.speeds)
    
    @property
    def avg_batch_size(self) -> float:
        if not self.batch_times:
            return 0.0
        return sum(b[0] for b in self.batch_times) / len(self.batch_times)
    
    @property
    def max_memory_usage(self) -> float:
        if not self.memory_samples:
            return 0.0
        return max(self.memory_samples)
    
    @property
    def avg_memory_usage(self) -> float:
        if not self.memory_samples:
            return 0.0
        return sum(self.memory_samples) / len(self.memory_samples)
    
    def get_eta_seconds(self) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        if self.records_per_second == 0:
            return 0.0
        
        remaining = self.total_records - self.processed_records
        eta = remaining / self.records_per_second
        
        # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ ETA
        self.eta_history.append(eta)
        if len(self.eta_history) > 1:
            return sum(self.eta_history) / len(self.eta_history)
        return eta
    
    def get_progress_string(self, metrics: ProcessingMetrics) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–æ–∫—É –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        if self.total_records == 0:
            return "–û–∂–∏–¥–∞–Ω–∏–µ..."
        
        # –í—Ä–µ–º—è
        elapsed = time.time() - self.start_time
        hours = int(elapsed // 3600)
        minutes = int((elapsed % 3600) // 60)
        seconds = int(elapsed % 60)
        
        # ETA
        eta_seconds = self.get_eta_seconds()
        eta_hours = int(eta_seconds // 3600)
        eta_minutes = int((eta_seconds % 3600) // 60)
        eta_seconds = int(eta_seconds % 60)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        try:
            memory_usage = psutil.virtual_memory().percent
            memory_status = "üü¢" if memory_usage < 60 else "üü°" if memory_usage < 80 else "üî¥"
        except:
            memory_usage = 0
            memory_status = "‚ö™"
        
        lines = [
            f"üìä {self.progress_percent:6.2f}% | üìà {self.processed_records:,}/{self.total_records:,}",
            f"‚ö° {self.records_per_second:.0f}/—Å–µ–∫ | ‚è±Ô∏è {hours:02d}:{minutes:02d}:{seconds:02d}",
            f"‚è≥ ETA: {eta_hours:02d}:{eta_minutes:02d}:{eta_seconds:02d} | üß† {memory_status} {memory_usage:5.1f}%",
            f"üñºÔ∏è {metrics.valid_images:,}‚úÖ {metrics.failed_images:,}‚ùå | üíæ {self.max_memory_usage/1024:.1f}GB"
        ]
        return " | ".join(lines)


class BatchProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –±–∞—Ç—á–µ–π —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, image_processor: ImageProcessorWithEmbedding, metrics: ProcessingMetrics):
        self.image_processor = image_processor
        self.metrics = metrics
        self.last_memory_check = time.time()
        self.memory_lock = asyncio.Lock()
        
    async def process_batch(self, batch_data: List[Tuple[str, str]]) -> List[FaceRecord]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∑–∞–ø–∏—Å–µ–π"""
        if not batch_data:
            return []
        
        batch_start_time = time.time()
        batch_size = len(batch_data)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        await self._check_memory_and_adjust()
        
        try:
            # –®–∞–≥ 1: –ë—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π –≤ –±–∞—Ç—á–µ
            lines = [line for line, _ in batch_data]
            parsed_records = parse_batch_records(lines, self.metrics)
            
            if not parsed_records:
                logger.debug(f"–ü—É—Å—Ç–æ–π –±–∞—Ç—á –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞: {batch_size} –∑–∞–ø–∏—Å–µ–π")
                return []
            
            # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            image_urls = []
            record_indices = []
            
            for i, record_data in enumerate(parsed_records):
                if record_data and record_data.get('image_url'):
                    image_urls.append(record_data['image_url'])
                    record_indices.append(i)
            
            # –®–∞–≥ 3: –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            image_results = []
            if image_urls:
                try:
                    image_results = await process_images_batch(
                        self.image_processor,
                        image_urls,
                        self.metrics
                    )
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –∑–∞–ø–∏—Å—è–º–∏ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            
            # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ FaceRecord
            face_records = self._create_face_records(
                parsed_records, 
                record_indices, 
                image_results
            )
            
            # –®–∞–≥ 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            batch_time = time.time() - batch_start_time
            self.metrics.add_batch_time(batch_time)
            
            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á –∏–∑ {batch_size} –∑–∞–ø–∏—Å–µ–π –∑–∞ {batch_time:.2f} —Å–µ–∫, —Å–æ–∑–¥–∞–Ω–æ {len(face_records)} –æ–±—ä–µ–∫—Ç–æ–≤")
            return face_records
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞: {e}", exc_info=True)
            return self._create_fallback_records(batch_data)
    
    def _create_face_records(self, parsed_records: List[Dict], 
                           record_indices: List[int], 
                           image_results: List) -> List[FaceRecord]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ FaceRecord –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        face_records = []
        image_result_idx = 0
        
        for i, record_data in enumerate(parsed_records):
            if not record_data:
                continue
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∑–∞–ø–∏—Å–∏
            try:
                record = FaceRecord(**record_data)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                if i in record_indices and image_result_idx < len(image_results):
                    img_result = image_results[image_result_idx]
                    image_result_idx += 1
                    
                    if img_result and isinstance(img_result, tuple) and len(img_result) >= 3:
                        filepath, base64_str, img_info = img_result
                        
                        if filepath and base64_str:
                            record.image_path = filepath
                            record.image_base64 = base64_str
                            if img_info:
                                record.image_width = img_info.get('width', 0)
                                record.image_height = img_info.get('height', 0)
                                record.image_size_kb = img_info.get('file_size_kb', 0)
                                record.download_time_ms = img_info.get('download_time_ms', 0)
                                record.is_cached = img_info.get('is_cached', False)
                            record.image_hash = hashlib.md5(record.image_url.encode()).hexdigest()
                        elif record.image_url:
                            record.failed_reason = img_info.get('failed_reason', '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏') if img_info else '–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏'
                            record.image_hash = hashlib.md5(record.image_url.encode()).hexdigest()
                
                face_records.append(record)
                
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è FaceRecord: {e}")
                continue
        
        return face_records
    
    async def _check_memory_and_adjust(self):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–º—è—Ç—å –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É"""
        async with self.memory_lock:
            current_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ —á–∞—â–µ —á–µ–º —Ä–∞–∑ –≤ 5 —Å–µ–∫—É–Ω–¥
            if current_time - self.last_memory_check < 5:
                return
            
            self.last_memory_check = current_time
            
            try:
                memory_percent = psutil.virtual_memory().percent
                available_gb = psutil.virtual_memory().available / (1024**3)
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
                if memory_percent > 90 or available_gb < 0.2:
                    logger.warning(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_percent:.1f}%, {available_gb:.2f}GB —Å–≤–æ–±–æ–¥–Ω–æ")
                    await asyncio.sleep(5)
                    gc.collect()
                elif memory_percent > 80 or available_gb < 0.5:
                    logger.debug(f"–í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_percent:.1f}%")
                    await asyncio.sleep(1)
                    gc.collect()
                elif memory_percent > 70:
                    await asyncio.sleep(0.5)
                    
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    def _create_fallback_records(self, batch_data: List[Tuple[str, str]]) -> List[FaceRecord]:
        """–°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏"""
        records = []
        parser = get_global_parser()
        
        for line, line_hash in batch_data:
            try:
                record_data = parser.parse_record(line, self.metrics)
                if record_data:
                    record = FaceRecord(**record_data)
                    records.append(record)
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è fallback –∑–∞–ø–∏—Å–∏: {e}")
                continue
        
        return records


class MemoryManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç—Ä–æ–ª–µ–º"""
    
    def __init__(self):
        self.peak_memory = 0
        self.memory_samples = deque(maxlen=200)
        self.last_cleanup = time.time()
        self.cleanup_interval = 60  # —Å–µ–∫—É–Ω–¥
        
    def is_memory_safe(self, additional_mb: float = 0) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±–µ–∑–æ–ø–∞—Å–Ω–æ –ª–∏ –≤—ã–¥–µ–ª—è—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–∞–º—è—Ç—å"""
        try:
            memory = psutil.virtual_memory()
            current_usage = memory.percent
            available_mb = memory.available / (1024**2)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∏–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            self.peak_memory = max(self.peak_memory, memory.used / (1024**3))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ç–º–ø–ª
            self.memory_samples.append({
                'time': time.time(),
                'percent': current_usage,
                'available_mb': available_mb,
                'used_gb': memory.used / (1024**3)
            })
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ª–æ–≤–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
            safe_percent = current_usage < Config.MAX_MEMORY_PERCENT
            safe_available = (available_mb - additional_mb) > 200  # –ú–∏–Ω–∏–º—É–º 200MB —Å–≤–æ–±–æ–¥–Ω–æ
            
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if not safe_percent or not safe_available:
                current_time = time.time()
                if current_time - self.last_cleanup > self.cleanup_interval:
                    self.perform_cleanup()
                    self.last_cleanup = current_time
            
            return safe_percent and safe_available
            
        except Exception:
            return True  # –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
    
    def perform_cleanup(self):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –ø–∞–º—è—Ç–∏"""
        logger.debug("–í—ã–ø–æ–ª–Ω—è—é –æ—á–∏—Å—Ç–∫—É –ø–∞–º—è—Ç–∏...")
        try:
            # –û—á–∏—â–∞–µ–º –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞
            parser = get_global_parser()
            if hasattr(parser, 'clear_cache'):
                parser.clear_cache()
                logger.debug("–û—á–∏—â–µ–Ω –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞")
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
            for _ in range(2):
                gc.collect()
            
            logger.info("–í—ã–ø–æ–ª–Ω–µ–Ω–∞ –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏")
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        if not self.memory_samples:
            return {
                'peak_memory_gb': 0,
                'avg_memory_percent': 0,
                'current_memory_percent': 0,
                'samples_count': 0
            }
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        avg_percent = sum(s['percent'] for s in self.memory_samples) / len(self.memory_samples)
        current_percent = self.memory_samples[-1]['percent'] if self.memory_samples else 0
        
        return {
            'peak_memory_gb': self.peak_memory,
            'avg_memory_percent': avg_percent,
            'current_memory_percent': current_percent,
            'samples_count': len(self.memory_samples),
            'last_cleanup': self.last_cleanup
        }


class OptimizedFaceRecognitionProcessor:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≤–µ—Ä—Ö–µ–¥ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
    - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
    - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    
    def __init__(self, formats: List[str], resume: bool = False):
        self.metrics = ProcessingMetrics()
        self.records: List[FaceRecord] = []
        self.image_processor = None
        self.formats = formats
        self.output_dir = ""
        self.resume = resume
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.batch_size = Config.INITIAL_BATCH_SIZE
        self.max_batch_size = 20000
        self.min_batch_size = 500
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.memory_manager = MemoryManager()
        self.batch_processor = None
        self.checkpoint_manager = None
        self.report_generator = None
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.processed_hashes: Set[str] = set()
        self.progress_stats = ProgressStats()
        self.is_running = True
        
        # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        self.metrics_lock = asyncio.Lock()
        self.records_lock = asyncio.Lock()
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω OptimizedFaceRecognitionProcessor —Å batch_size={self.batch_size}")
    
    async def process_file(self, input_file: str) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        logger.info(f"üéØ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {os.path.basename(input_file)}")
        
        # –ù–∞—á–∞–ª–æ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–∞–º—è—Ç–∏
        tracemalloc.start()
        
        try:
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫
            print("üîç –ü–æ–¥—Å—á–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ —Ñ–∞–π–ª–µ...")
            total_lines = await self._count_lines_optimized(input_file)
            if total_lines == 0:
                logger.error("–§–∞–π–ª –ø—É—Å—Ç")
                return False
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {total_lines:,}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self.output_dir = Config.setup_directories()
            print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.output_dir}")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            await self._initialize_components(input_file, total_lines)
            
            # –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            return await self._run_processing_pipeline(input_file, total_lines)
            
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            await self._save_checkpoint_before_exit(input_file)
            return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", exc_info=True)
            return False
        finally:
            await self._final_cleanup()
    
    async def _initialize_components(self, input_file: str, total_lines: int):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        self.checkpoint_manager = CheckpointManager(self.output_dir)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        start_position, _ = await self._load_checkpoint_state(input_file, total_lines)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–∫–µ—Ä–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.progress_stats = ProgressStats(total_records=total_lines)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        self.image_processor = ImageProcessorWithEmbedding(self.output_dir)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞—Ç—á-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        self.batch_processor = BatchProcessor(self.image_processor, self.metrics)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤
        self.report_generator = ReportGenerator(self.output_dir)
    
    async def _run_processing_pipeline(self, input_file: str, total_lines: int) -> bool:
        """–ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print("\n" + "="*80)
        print("üöÄ –ù–ê–ß–ê–õ–û –û–ë–†–ê–ë–û–¢–ö–ò")
        print("="*80)
        
        async with self.image_processor:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á
            processing_task = asyncio.create_task(
                self._process_file_stream(input_file, total_lines)
            )
            progress_task = asyncio.create_task(self._display_progress())
            
            try:
                # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                success = await processing_task
                
                if success:
                    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
                    await self._finalize_processing()
                    return True
                else:
                    return False
                    
            except KeyboardInterrupt:
                print("\n‚ö†Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                self.is_running = False
                success = False
                
                # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á
                try:
                    await asyncio.wait_for(processing_task, timeout=5.0)
                except (asyncio.TimeoutError, asyncio.CancelledError):
                    pass
                
                await self._save_checkpoint_before_exit(input_file)
                return False
            finally:
                # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á
                self.is_running = False
                progress_task.cancel()
                try:
                    await progress_task
                except asyncio.CancelledError:
                    pass
    
    async def _process_file_stream(self, input_file: str, total_lines: int) -> bool:
        """–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
        try:
            # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–µ–π
            buffer_size = 1024 * 1024 * 20  # 20MB –±—É—Ñ–µ—Ä
            
            with open(input_file, 'r', encoding='utf-8', buffering=buffer_size) as f:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é
                start_position = await self._get_start_position()
                if start_position > 0:
                    f.seek(start_position)
                    logger.info(f"–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –ø–æ–∑–∏—Ü–∏–∏: {start_position:,} –±–∞–π—Ç")
                
                batch_data = []
                batch_count = 0
                current_position = start_position
                batch_start_time = time.time()
                
                # –ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
                for line in f:
                    if not self.is_running:
                        break
                    
                    line = line.strip()
                    if not line:
                        continue
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ —Ñ–∞–π–ª–µ
                    current_position += len(line.encode('utf-8')) + 1  # +1 –¥–ª—è —Å–∏–º–≤–æ–ª–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö—ç—à —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                    line_hash = hashlib.md5(line.encode()).hexdigest()[:16]
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç
                    if line_hash in self.processed_hashes:
                        async with self.metrics_lock:
                            self.metrics.duplicate_records += 1
                        continue
                    
                    batch_data.append((line, line_hash))
                    self.processed_hashes.add(line_hash)
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞
                    if len(batch_data) >= self.batch_size:
                        await self._process_batch(
                            batch_data, 
                            current_position, 
                            batch_count, 
                            batch_start_time,
                            input_file,
                            total_lines
                        )
                        
                        batch_data = []
                        batch_count += 1
                        
                        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
                        self._adjust_batch_size_dynamically(batch_count)
                        
                        # –°–±—Ä–æ—Å –≤—Ä–µ–º–µ–Ω–∏ —Å—Ç–∞—Ä—Ç–∞ –±–∞—Ç—á–∞
                        batch_start_time = time.time()
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞—Ç–∫–∞
                if batch_data:
                    await self._process_batch(
                        batch_data, 
                        current_position, 
                        batch_count, 
                        batch_start_time,
                        input_file,
                        total_lines
                    )
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", exc_info=True)
            return False
    
    async def _process_batch(self, batch_data: List[Tuple[str, str]], 
                           current_position: int, 
                           batch_count: int,
                           batch_start_time: float,
                           input_file: str = None,
                           total_lines: int = 0):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –±–∞—Ç—á –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞
        batch_records = await self.batch_processor.process_batch(batch_data)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        async with self.metrics_lock:
            processed_in_batch = len(batch_data)
            self.metrics.total_records += processed_in_batch
            self.metrics.processed_records += len(batch_records)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
        async with self.records_lock:
            self.records.extend(batch_records)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if self.metrics.processed_records % 1000 == 0:
            memory_usage_mb = psutil.virtual_memory().used / (1024**2)
            self.progress_stats.update(
                self.metrics.processed_records,
                processed_in_batch,
                memory_usage_mb
            )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        if self.metrics.processed_records % Config.CHECKPOINT_INTERVAL == 0:
            await self._save_checkpoint_with_state(input_file, total_lines, current_position)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
        if batch_count % 20 == 0:
            await self._optimize_memory_usage()
    
    async def _optimize_memory_usage(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–∞—Ä—Å–µ—Ä–∞
            parser = get_global_parser()
            if hasattr(parser, '_cache') and len(parser._cache) > 25000:
                parser.clear_cache()
                logger.debug(f"–û—á–∏—â–µ–Ω –∫—ç—à –ø–∞—Ä—Å–µ—Ä–∞")
            
            # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –µ—Å–ª–∏ –∏—Ö –º–Ω–æ–≥–æ
            if len(self.records) > 10000:
                await self._save_records_intermediate()
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
            gc.collect()
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {e}")
    
    async def _save_records_intermediate(self):
        """–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        try:
            if len(self.records) < 5000:
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–æ–≤–∏–Ω—É –∑–∞–ø–∏—Å–µ–π
            save_count = len(self.records) // 2
            records_to_save = self.records[:save_count]
            
            temp_file = os.path.join(
                self.output_dir,
                Config.TEMP_FOLDER,
                f"records_temp_{int(time.time())}.jsonl"
            )
            
            os.makedirs(os.path.dirname(temp_file), exist_ok=True)
            
            # –ë—ã—Å—Ç—Ä–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è
            with open(temp_file, 'w', encoding='utf-8') as f:
                for record in records_to_save:
                    f.write(json.dumps(record.to_dict()) + '\n')
            
            # –£–¥–∞–ª—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
            async with self.records_lock:
                del self.records[:save_count]
            
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {save_count} –∑–∞–ø–∏—Å–µ–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–∞–ø–∏—Å–µ–π: {e}")
    
    async def _display_progress(self):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        last_update = 0
        
        while self.is_running:
            try:
                current_time = time.time()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                if current_time - last_update >= 5.0:
                    progress_str = self.progress_stats.get_progress_string(self.metrics)
                    sys.stdout.write('\r' + progress_str + ' ' * 10)
                    sys.stdout.flush()
                    last_update = current_time
                
                await asyncio.sleep(2)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}")
                await asyncio.sleep(2)
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        if hasattr(self, 'progress_stats'):
            progress_str = self.progress_stats.get_progress_string(self.metrics)
            sys.stdout.write('\r' + progress_str + ' ' * 10 + '\n')
            sys.stdout.flush()
    
    async def _finalize_processing(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤"""
        print("\n" + "="*80)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        print("="*80)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"‚úÖ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.metrics.total_records:,}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.valid_images:,}")
        print(f"‚ö†Ô∏è  –ù–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫: {self.metrics.failed_images:,}")
        print(f"‚ùå –û—à–∏–±–æ–∫ JSON: {self.metrics.json_errors:,}")
        print(f"üíæ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.cached_images:,}")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.metrics.elapsed_time:.1f} —Å–µ–∫")
        
        if self.metrics.elapsed_time > 0:
            print(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {self.metrics.total_records / self.metrics.elapsed_time:.0f} –∑–∞–ø–∏—Å–µ–π/—Å–µ–∫")
        
        print("‚îÄ" * 80)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"üè¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π: {len(self.metrics.unique_companies)}")
        print(f"üë§ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {len(self.metrics.unique_users)}")
        print(f"üì± –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤: {len(self.metrics.unique_devices)}")
        print(f"üåê –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö IP: {len(self.metrics.unique_ips)}")
        print("="*80)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        if self.formats:
            print("\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤...")
            await self._generate_reports()
        
        print("\n" + "="*80)
        print("‚ú® –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("="*80)
    
    async def _generate_reports(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤"""
        reports_created = []
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –µ—Å–ª–∏ –µ—Å—Ç—å
        await self._load_saved_records()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
        if "HTML" in self.formats:
            print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ HTML –æ—Ç—á–µ—Ç–∞...")
            try:
                html_report = self.report_generator.generate_html_report(self.records, self.metrics)
                if html_report:
                    reports_created.append(("üåê HTML –æ—Ç—á–µ—Ç", html_report))
                    print("‚úÖ HTML –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è HTML –æ—Ç—á–µ—Ç–∞: {e}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ README —Ñ–∞–π–ª–∞
        self._create_readme(reports_created)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        print("\nüéâ –û–¢–ß–ï–¢–´ –£–°–ü–ï–®–ù–û –°–û–ó–î–ê–ù–´")
        print("="*80)
        print(f"üìÅ –ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏: {self.output_dir}")
        
        for report_name, report_path in reports_created:
            if report_path:
                print(f"   ‚Ä¢ {report_name}: {os.path.basename(report_path)}")
        
        print(f"üñºÔ∏è  –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.join(self.output_dir, Config.IMAGE_FOLDER)}")
        print("="*80)
    
    def _create_readme(self, reports_created: List[Tuple[str, str]]):
        """–°–æ–∑–¥–∞–Ω–∏–µ README —Ñ–∞–π–ª–∞"""
        memory_stats = self.memory_manager.get_statistics()
        
        readme_content = f"""
# –û–¢–ß–ï–¢ –ü–û –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Æ –õ–ò–¶

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.datetime.now().strftime("%d.%m.%Y %H:%M:%S")}
- –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {self.metrics.total_records:,}
- –£—Å–ø–µ—à–Ω—ã—Ö —Ñ–æ—Ç–æ: {self.metrics.valid_images:,}
- –û—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏: {self.metrics.failed_images:,}
- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {self.metrics.elapsed_time:.1f} —Å–µ–∫
- –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {memory_stats.get('peak_memory_gb', 0):.1f} GB

## üöÄ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏:
‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–∞–π–ª–æ–≤ –±–æ–ª–µ–µ 2 –ì–ë
‚úÖ –í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
‚úÖ –ö–æ–Ω—Ç—Ä–æ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ (–¥–æ 85% –û–ó–£)
‚úÖ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞
‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–≤–µ—Ä—Ö–µ–¥ –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é
‚úÖ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
"""
        
        for report_name, report_path in reports_created:
            if report_path:
                readme_content += f"- {report_name}: {os.path.basename(report_path)}\n"
        
        readme_path = os.path.join(self.output_dir, "README.txt")
        try:
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è README —Ñ–∞–π–ª–∞: {e}")
    
    async def _load_saved_records(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_dir = os.path.join(self.output_dir, Config.TEMP_FOLDER)
        if not os.path.exists(temp_dir):
            return
        
        try:
            temp_files = []
            for filename in os.listdir(temp_dir):
                if filename.startswith('records_temp_') and filename.endswith('.jsonl'):
                    filepath = os.path.join(temp_dir, filename)
                    temp_files.append((os.path.getmtime(filepath), filepath))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            temp_files.sort()
            
            loaded_count = 0
            for _, filepath in temp_files:
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        for line in f:
                            if line.strip():
                                data = json.loads(line.strip())
                                record = FaceRecord(**data)
                                async with self.records_lock:
                                    self.records.append(record)
                                loaded_count += 1
                    
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    os.remove(filepath)
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {filepath}: {e}")
            
            if loaded_count > 0:
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} –∑–∞–ø–∏—Å–µ–π –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {e}")
    
    async def _load_checkpoint_state(self, input_file: str, total_lines: int) -> Tuple[int, Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        if not self.resume:
            print("üîÑ –†–µ–∂–∏–º: –ù–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê")
            return 0, {}
        
        if not self.checkpoint_manager:
            print("üîÑ –†–µ–∂–∏–º: –ù–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (—á–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)")
            return 0, {}
        
        checkpoint_state = self.checkpoint_manager.load_checkpoint()
        if not checkpoint_state:
            print("üîÑ –†–µ–∂–∏–º: –ù–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (—á–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω)")
            return 0, {}
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        is_valid, message = self.checkpoint_manager.validate_checkpoint(input_file)
        if not is_valid:
            print(f"üîÑ –†–µ–∂–∏–º: –ù–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê (—á–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ–≤–∞–ª–∏–¥–µ–Ω: {message})")
            self.checkpoint_manager.clear_checkpoint()
            return 0, {}
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        print(f"üîÑ –†–µ–∂–∏–º: –í–û–ó–û–ë–ù–û–í–õ–ï–ù–ò–ï –ü–†–û–¶–ï–°–°–ê")
        print(f"üìä –ù–∞–π–¥–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç: {checkpoint_state.processed_lines:,}/{checkpoint_state.total_lines:,}")
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.metrics.valid_images = checkpoint_state.valid_images
        self.metrics.failed_images = checkpoint_state.failed_images
        self.metrics.json_errors = checkpoint_state.json_errors
        self.metrics.cached_images = checkpoint_state.cached_images
        self.metrics.network_errors = checkpoint_state.network_errors
        self.metrics.timeout_errors = checkpoint_state.timeout_errors
        self.metrics.duplicate_records = checkpoint_state.duplicate_records
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self.metrics.unique_users = set(checkpoint_state.unique_users)
        self.metrics.unique_devices = set(checkpoint_state.unique_devices)
        self.metrics.unique_companies = set(checkpoint_state.unique_companies)
        self.metrics.unique_ips = set(checkpoint_state.unique_ips)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö—ç—à–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        self.processed_hashes = set(checkpoint_state.records_processed)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        self.batch_size = checkpoint_state.batch_size
        
        return checkpoint_state.last_position, checkpoint_state.__dict__
    
    async def _get_start_position(self) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if self.checkpoint_manager and self.checkpoint_manager.state:
            return self.checkpoint_manager.state.last_position
        return 0
    
    async def _save_checkpoint_with_state(self, input_file: str, total_lines: int, position: int):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç —Å —Ç–µ–∫—É—â–∏–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º"""
        if not self.checkpoint_manager:
            return
        
        try:
            self.checkpoint_manager.save_checkpoint(
                file_name=os.path.basename(input_file),
                total_lines=total_lines,
                processed_lines=self.metrics.total_records,
                valid_images=self.metrics.valid_images,
                failed_images=self.metrics.failed_images,
                json_errors=self.metrics.json_errors,
                cached_images=self.metrics.cached_images,
                network_errors=self.metrics.network_errors,
                timeout_errors=self.metrics.timeout_errors,
                duplicate_records=self.metrics.duplicate_records,
                last_position=position,
                batch_size=self.batch_size,
                records_processed=list(self.processed_hashes),
                unique_users=list(self.metrics.unique_users),
                unique_devices=list(self.metrics.unique_devices),
                unique_companies=list(self.metrics.unique_companies),
                unique_ips=list(self.metrics.unique_ips)
            )
            
            logger.debug(f"–ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {self.metrics.total_records:,} –∑–∞–ø–∏—Å–µ–π")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
    
    async def _save_checkpoint_before_exit(self, input_file: str):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º"""
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é
            if os.path.exists(input_file):
                file_size = os.path.getsize(input_file)
                estimated_position = int(file_size * (self.progress_stats.progress_percent / 100))
                
                await self._save_checkpoint_with_state(
                    input_file,
                    self.progress_stats.total_records,
                    estimated_position
                )
                
                print("üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ: {e}")
    
    def _adjust_batch_size_dynamically(self, batch_count: int):
        """–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞"""
        try:
            memory_percent = psutil.virtual_memory().percent
            available_gb = psutil.virtual_memory().available / (1024**3)
            cpu_percent = psutil.cpu_percent(interval=0.1)
            
            new_batch_size = self.batch_size
            
            # –†–µ–≥—É–ª–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≥—Ä—É–∑–∫–∏
            if memory_percent > 85 or cpu_percent > 80 or available_gb < 0.5:
                # –í—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ - —É–º–µ–Ω—å—à–∞–µ–º
                new_batch_size = max(self.min_batch_size, int(self.batch_size * 0.5))
            elif memory_percent > 70 or cpu_percent > 60:
                # –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞ - –Ω–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∞–µ–º
                new_batch_size = max(self.min_batch_size, int(self.batch_size * 0.7))
            elif memory_percent < 40 and cpu_percent < 40 and self.batch_size < self.max_batch_size:
                # –ù–∏–∑–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º
                new_batch_size = min(self.max_batch_size, int(self.batch_size * 1.5))
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å
            if new_batch_size != self.batch_size and batch_count % 10 == 0:
                logger.info(f"–ò–∑–º–µ–Ω–µ–Ω —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size:,} ‚Üí {new_batch_size:,}")
                self.batch_size = new_batch_size
                
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞: {e}")
    
    async def _count_lines_optimized(self, file_path: str) -> int:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ"""
        loop = asyncio.get_event_loop()
        
        def count_lines_sync():
            count = 0
            buffer_size = 1024 * 1024 * 16  # 16MB –±—É—Ñ–µ—Ä
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore', buffering=buffer_size) as f:
                while True:
                    buffer = f.read(buffer_size)
                    if not buffer:
                        break
                    count += buffer.count('\n')
            
            return count
        
        with ThreadPoolExecutor(max_workers=1) as executor:
            result = await loop.run_in_executor(executor, count_lines_sync)
        
        return result
    
    async def _final_cleanup(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        try:
            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–∞–º—è—Ç–∏
            if tracemalloc.is_tracing():
                snapshot = tracemalloc.take_snapshot()
                top_stats = snapshot.statistics('lineno')[:5]
                
                logger.info("–¢–æ–ø-5 —Å—Ç—Ä–æ–∫ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –ø–∞–º—è—Ç–∏:")
                for stat in top_stats:
                    logger.info(f"{stat}")
                
                tracemalloc.stop()
            
            # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–∞—Ä—Å–µ—Ä–∞
            parser = get_global_parser()
            if hasattr(parser, 'clear_cache'):
                parser.clear_cache()
            
            # –û—á–∏—Å—Ç–∫–∞ —Å–ø–∏—Å–∫–æ–≤
            async with self.records_lock:
                self.records.clear()
            
            self.processed_hashes.clear()
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –º—É—Å–æ—Ä–∞
            for _ in range(2):
                gc.collect()
            
            logger.info("–í—ã–ø–æ–ª–Ω–µ–Ω–∞ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ: {e}")

    def get_performance_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        memory_stats = self.memory_manager.get_statistics()
        
        return {
            'total_processed': self.metrics.processed_records,
            'total_records': self.metrics.total_records,
            'valid_images': self.metrics.valid_images,
            'failed_images': self.metrics.failed_images,
            'duplicate_records': self.metrics.duplicate_records,
            'peak_memory_gb': memory_stats['peak_memory_gb'],
            'avg_memory_percent': memory_stats['avg_memory_percent'],
            'current_memory_percent': memory_stats['current_memory_percent'],
            'processing_speed_avg': self.progress_stats.records_per_second,
            'total_time_seconds': time.time() - self.progress_stats.start_time,
            'memory_samples_count': memory_stats['samples_count']
        }


def get_optimized_processor(formats: List[str], resume: bool = False) -> OptimizedFaceRecognitionProcessor:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    return OptimizedFaceRecognitionProcessor(formats, resume)