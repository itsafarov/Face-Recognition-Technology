"""
–ú–µ–Ω–µ–¥–∂–µ—Ä —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å—é
"""

import os
import json
import time
import shutil
import hashlib
import logging
from typing import Dict, Any, Optional, List, Set, Tuple
from dataclasses import dataclass, asdict, field, fields, is_dataclass
from datetime import datetime, timedelta
from pathlib import Path

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from .config import Config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)


@dataclass
class CheckpointState:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    file_name: str = ""
    total_lines: int = 0
    processed_lines: int = 0
    valid_images: int = 0
    failed_images: int = 0
    json_errors: int = 0
    cached_images: int = 0
    network_errors: int = 0
    timeout_errors: int = 0
    duplicate_records: int = 0
    last_position: int = 0  # –ü–æ–∑–∏—Ü–∏—è –≤ —Ñ–∞–π–ª–µ (–±–∞–π—Ç—ã)
    timestamp: float = field(default_factory=time.time)
    batch_size: int = field(default_factory=lambda: Config.INITIAL_BATCH_SIZE)
    records_processed: List[str] = field(default_factory=list)
    unique_users: List[str] = field(default_factory=list)
    unique_devices: List[str] = field(default_factory=list)
    unique_companies: List[str] = field(default_factory=list)
    unique_ips: List[str] = field(default_factory=list)
    
    def __post_init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π
        self._normalize_numeric_fields()
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        self._validate_data()
    
    def _normalize_numeric_fields(self):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π"""
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º batch_size –≤ int –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
        try:
            self.batch_size = int(self.batch_size)
            if self.batch_size < 100:
                self.batch_size = Config.INITIAL_BATCH_SIZE
            elif self.batch_size > 50000:
                self.batch_size = 50000
        except (ValueError, TypeError):
            self.batch_size = Config.INITIAL_BATCH_SIZE
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥—Ä—É–≥–∏—Ö —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π
        numeric_fields = [
            'total_lines', 'processed_lines', 'valid_images', 
            'failed_images', 'json_errors', 'cached_images',
            'network_errors', 'timeout_errors', 'duplicate_records',
            'last_position'
        ]
        
        for field_name in numeric_fields:
            value = getattr(self, field_name, 0)
            try:
                setattr(self, field_name, int(float(value)))
            except (ValueError, TypeError):
                setattr(self, field_name, 0)
        
        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —á—Ç–æ timestamp - float
        try:
            self.timestamp = float(self.timestamp)
        except (ValueError, TypeError):
            self.timestamp = time.time()
    
    def _validate_data(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
        if self.processed_lines > self.total_lines > 0:
            logger.warning(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫ ({self.processed_lines:,}) > –≤—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ ({self.total_lines:,})")
            self.processed_lines = min(self.processed_lines, self.total_lines)
        
        if self.last_position < 0:
            logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è: {self.last_position:,}")
            self.last_position = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        total_images = self.valid_images + self.failed_images
        if total_images > self.processed_lines:
            logger.warning(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({total_images}) > –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ ({self.processed_lines})")
    
    @property
    def progress_percent(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"""
        if self.total_lines == 0:
            return 0.0
        return (self.processed_lines / self.total_lines) * 100
    
    @property
    def age_seconds(self) -> float:
        """–í–æ–∑—Ä–∞—Å—Ç —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        return time.time() - self.timestamp
    
    @property
    def age_hours(self) -> float:
        """–í–æ–∑—Ä–∞—Å—Ç —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –≤ —á–∞—Å–∞—Ö"""
        return self.age_seconds / 3600
    
    def is_expired(self, max_age_hours: float = 168) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω–µ –∏—Å—Ç–µ–∫ –ª–∏ —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 7 –¥–Ω–µ–π)"""
        return self.age_hours > max_age_hours
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        data = {}
        
        for field_info in fields(self):
            value = getattr(self, field_info.name)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            if isinstance(value, (set, list)):
                data[field_info.name] = list(value)
            elif is_dataclass(value):
                data[field_info.name] = asdict(value)
            else:
                data[field_info.name] = value
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—ã—á–∏—Å–ª—è–µ–º—ã–µ –ø–æ–ª—è
        data['progress_percent'] = self.progress_percent
        data['age_seconds'] = self.age_seconds
        data['age_hours'] = self.age_hours
        data['is_expired'] = self.is_expired()
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        if self.timestamp > 0:
            dt = datetime.fromtimestamp(self.timestamp)
            data['timestamp_human'] = dt.strftime("%Y-%m-%d %H:%M:%S")
            data['timestamp_iso'] = dt.isoformat()
        
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CheckpointState':
        """–°–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–∫—Ç –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª—è dataclass
        field_names = {f.name for f in fields(cls)}
        filtered_data = {k: v for k, v in data.items() if k in field_names}
        return cls(**filtered_data)


class CheckpointIntegrityError(Exception):
    """–û—à–∏–±–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
    pass


class CheckpointManager:
    """
    –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏ –¥–ª—è –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ù–∞–¥–µ–∂–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –∞—Ç–æ–º–∞—Ä–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
    - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
    - –ö–æ–Ω—Ç—Ä–æ–ª—å –≤–µ—Ä—Å–∏–π —Ñ–æ—Ä–º–∞—Ç–∞
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    """
    
    # –í–µ—Ä—Å–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
    CHECKPOINT_VERSION = 1
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.checkpoint_file = os.path.join(output_dir, Config.CHECKPOINT_FILE)
        self.checkpoint_temp = f"{self.checkpoint_file}.tmp"
        self.checkpoint_backup = f"{self.checkpoint_file}.backup"
        self.checkpoint_archive = f"{self.checkpoint_file}.archive"
        
        self.state: Optional[CheckpointState] = None
        self.last_save = 0.0
        self.save_count = 0
        self.checksum: Optional[str] = None
        
        # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self._cache: Dict[str, Tuple[CheckpointState, float]] = {}
        self._cache_ttl = 60  # —Å–µ–∫—É–Ω–¥
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'loads': 0,
            'saves': 0,
            'backup_restores': 0,
            'integrity_errors': 0,
            'last_operation': None
        }
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        os.makedirs(os.path.dirname(self.checkpoint_file), exist_ok=True)
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω CheckpointManager: {self.checkpoint_file}")
    
    def _update_stats(self, operation: str):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø–µ—Ä–∞—Ü–∏–π"""
        self.stats['last_operation'] = operation
        key = f'{operation}s'
        self.stats[key] = self.stats.get(key, 0) + 1
    
    def _generate_checksum(self, data: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã –¥–ª—è –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
            return hashlib.sha256(data_str.encode()).hexdigest()[:32]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã: {e}")
            return "0" * 32
    
    def _calculate_file_checksum(self, filepath: str) -> Optional[str]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É —Ñ–∞–π–ª–∞"""
        if not os.path.exists(filepath):
            return None
        
        try:
            with open(filepath, 'rb') as f:
                file_hash = hashlib.sha256()
                # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –±–ª–æ–∫–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                for chunk in iter(lambda: f.read(4096), b""):
                    file_hash.update(chunk)
                return file_hash.hexdigest()
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return None
    
    def validate_checkpoint_integrity(self, checkpoint_data: Dict[str, Any]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        try:
            required_fields = {
                'file_name', 'total_lines', 'processed_lines', 
                'last_position', 'timestamp', 'batch_size'
            }
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            missing_fields = required_fields - set(checkpoint_data.keys())
            if missing_fields:
                logger.warning(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è: {missing_fields}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            type_checks = [
                ('processed_lines', (int, float)),
                ('total_lines', (int, float)),
                ('last_position', (int, float)),
                ('batch_size', (int, float)),
                ('timestamp', (int, float)),
            ]
            
            for field_name, expected_types in type_checks:
                value = checkpoint_data.get(field_name)
                if not isinstance(value, expected_types):
                    logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø {field_name}: {type(value)}")
                    return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
            if checkpoint_data['processed_lines'] > checkpoint_data['total_lines']:
                logger.warning(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫ ({checkpoint_data['processed_lines']:,}) > –≤—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ ({checkpoint_data['total_lines']:,})")
                return False
            
            if checkpoint_data['last_position'] < 0:
                logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è: {checkpoint_data['last_position']:,}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö)
            checkpoint_age = time.time() - checkpoint_data['timestamp']
            if checkpoint_age > 30 * 24 * 3600:  # 30 –¥–Ω–µ–π
                logger.warning(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –æ—á–µ–Ω—å —Å—Ç–∞—Ä: {checkpoint_age/3600/24:.1f} –¥–Ω–µ–π")
            elif checkpoint_age > 7 * 24 * 3600:  # 7 –¥–Ω–µ–π
                logger.info(f"–ß–µ–∫–ø–æ–∏–Ω—Ç —Å—Ç–∞—Ä: {checkpoint_age/3600/24:.1f} –¥–Ω–µ–π")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö
            try:
                batch_size = int(checkpoint_data['batch_size'])
                if not (100 <= batch_size <= 50000):
                    logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size:,}")
                    return False
            except (ValueError, TypeError):
                logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ç–∏–ø —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'checksum' in checkpoint_data:
                data_copy = checkpoint_data.copy()
                saved_checksum = data_copy.pop('checksum')
                calculated_checksum = self._generate_checksum(data_copy)
                
                if saved_checksum != calculated_checksum:
                    logger.warning("–ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–∞—è —Å—É–º–º–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç")
                    self.stats['integrity_errors'] += 1
                    return False
            
            logger.debug(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏")
            return True
            
        except (TypeError, KeyError, ValueError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
            self.stats['integrity_errors'] += 1
            return False
    
    def _safe_json_load(self, filepath: str) -> Optional[Dict[str, Any]]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ JSON —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
        if not os.path.exists(filepath):
            return None
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ {filepath}: {e}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ñ–∞–π–ª
            try:
                backup_content = self._try_recover_json(filepath)
                if backup_content:
                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω JSON –∏–∑ {filepath}")
                    return backup_content
            except Exception as recovery_error:
                logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è JSON: {recovery_error}")
            
            return None
        except UnicodeDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –≤ —Ñ–∞–π–ª–µ {filepath}: {e}")
            return None
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {filepath}: {e}")
            return None
    
    def _try_recover_json(self, filepath: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏ –∏–∑–≤–ª–µ—á—å JSON
            start_idx = content.find('{')
            end_idx = content.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_str = content[start_idx:end_idx + 1]
                return json.loads(json_str)
            
            return None
        except Exception as e:
            logger.debug(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ JSON –Ω–µ —É–¥–∞–ª–æ—Å—å: {e}")
            return None
    
    def load_checkpoint(self) -> Optional[CheckpointState]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        cache_key = f"checkpoint_{self.checkpoint_file}"
        current_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        if cache_key in self._cache:
            cached_data, timestamp = self._cache[cache_key]
            if current_time - timestamp < self._cache_ttl:
                logger.debug("–ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑ –∫—ç—à–∞")
                self.state = cached_data
                self._update_stats('load')
                return self.state
        
        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
        self._cache.clear()
        
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –∏–∑ {self.checkpoint_file}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if os.path.exists(self.checkpoint_file):
            try:
                data = self._safe_json_load(self.checkpoint_file)
                if data is None:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª, –ø—Ä–æ–±—É—é —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é")
                    return self._load_backup_checkpoint()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é —Ñ–æ—Ä–º–∞—Ç–∞
                if data.get('version', 0) != self.CHECKPOINT_VERSION:
                    logger.warning(f"–ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–∞—è –≤–µ—Ä—Å–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {data.get('version')}")
                    # –ú–æ–∂–µ–º –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –Ω–æ –ø–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    return self._load_backup_checkpoint()
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
                if not self.validate_checkpoint_integrity(data):
                    logger.warning("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞")
                    return self._load_backup_checkpoint()
                
                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è
                self.state = CheckpointState.from_dict(data)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É
                self.checksum = data.get('checksum')
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                self._cache[cache_key] = (self.state, current_time)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self._update_stats('load')
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —á–µ–∫–ø–æ–∏–Ω—Ç: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {self.state.processed_lines:,} –∏–∑ {self.state.total_lines:,} –∑–∞–ø–∏—Å–µ–π")
                logger.info(f"–ü–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∑–∏—Ü–∏—è: {self.state.last_position:,} –±–∞–π—Ç")
                logger.info(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.state.batch_size:,}")
                logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {self.state.progress_percent:.1f}%")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
                if self.state.is_expired():
                    logger.warning(f"–ß–µ–∫–ø–æ–∏–Ω—Ç —É—Å—Ç–∞—Ä–µ–ª: {self.state.age_hours:.1f} —á–∞—Å–æ–≤")
                
                return self.state
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
                return self._load_backup_checkpoint()
        
        # –§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        logger.info("–ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None
    
    def _load_backup_checkpoint(self) -> Optional[CheckpointState]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        if not os.path.exists(self.checkpoint_backup):
            logger.info("–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
        
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –∏–∑ {self.checkpoint_backup}")
        
        try:
            data = self._safe_json_load(self.checkpoint_backup)
            if data is None:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é")
                return None
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
            if not self.validate_checkpoint_integrity(data):
                logger.warning("–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞ –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self.state = CheckpointState.from_dict(data)
            self.checksum = data.get('checksum')
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats['backup_restores'] += 1
            self._update_stats('load')
            
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ä–µ–∑–µ—Ä–≤–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {self.state.processed_lines:,} –∑–∞–ø–∏—Å–µ–π")
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            try:
                self._atomic_save(self.checkpoint_backup, self.checkpoint_file)
                logger.info("–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
            except Exception as e:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
            
            return self.state
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
            return None
    
    def _atomic_save(self, source: str, destination: str):
        """–ê—Ç–æ–º–∞—Ä–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            temp_file = f"{destination}.atomic.tmp"
            
            # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
            shutil.copy2(source, temp_file)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω
            if os.path.exists(temp_file):
                dest_size = os.path.getsize(temp_file)
                src_size = os.path.getsize(source)
                
                if dest_size == src_size:
                    # –ê—Ç–æ–º–∞—Ä–Ω–æ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º
                    os.replace(temp_file, destination)
                    logger.debug(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {dest_size} –±–∞–π—Ç")
                else:
                    os.remove(temp_file)
                    raise IOError(f"–†–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: {src_size} != {dest_size}")
            else:
                raise IOError("–í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {source} -> {destination}: {e}")
            raise
    
    def save_checkpoint(self,
                       file_name: str,
                       total_lines: int,
                       processed_lines: int,
                       valid_images: int,
                       failed_images: int,
                       json_errors: int,
                       cached_images: int,
                       network_errors: int,
                       timeout_errors: int,
                       duplicate_records: int,
                       last_position: int,
                       batch_size: int,
                       records_processed: list,
                       unique_users: list,
                       unique_devices: list,
                       unique_companies: list,
                       unique_ips: list) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –æ–¥–Ω–æ–≥–æ –∏–∑ —É—Å–ª–æ–≤–∏–π:
        1. –†–∞–∑ –≤ 60 —Å–µ–∫—É–Ω–¥
        2. –ö–∞–∂–¥—ã–µ CHECKPOINT_INTERVAL –∑–∞–ø–∏—Å–µ–π
        3. –ü—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        
        Returns:
            bool: True –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, False –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        current_time = time.time()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
        time_condition = current_time - self.last_save >= 60
        records_condition = False
        
        if self.state:
            records_since_last = processed_lines - self.state.processed_lines
            records_condition = records_since_last >= Config.CHECKPOINT_INTERVAL
        
        completion_condition = processed_lines >= total_lines and total_lines > 0
        
        if not (time_condition or records_condition or completion_condition):
            return False
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        checkpoint_data = {
            'version': self.CHECKPOINT_VERSION,
            'file_name': file_name,
            'total_lines': total_lines,
            'processed_lines': processed_lines,
            'valid_images': valid_images,
            'failed_images': failed_images,
            'json_errors': json_errors,
            'cached_images': cached_images,
            'network_errors': network_errors,
            'timeout_errors': timeout_errors,
            'duplicate_records': duplicate_records,
            'last_position': last_position,
            'timestamp': current_time,
            'batch_size': batch_size,
            'records_processed': records_processed,
            'unique_users': unique_users,
            'unique_devices': unique_devices,
            'unique_companies': unique_companies,
            'unique_ips': unique_ips,
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Å—É–º–º—É
        checksum = self._generate_checksum(checkpoint_data)
        checkpoint_data['checksum'] = checksum
        
        try:
            # –®–∞–≥ 1: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with open(self.checkpoint_temp, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False, default=str)
            
            # –®–∞–≥ 2: –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            if os.path.exists(self.checkpoint_file):
                try:
                    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤–Ω—É—é –∫–æ–ø–∏—é –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
                    if os.path.exists(self.checkpoint_backup):
                        try:
                            shutil.copy2(self.checkpoint_backup, self.checkpoint_archive)
                        except Exception:
                            pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
                    shutil.copy2(self.checkpoint_file, self.checkpoint_backup)
                    logger.debug("–°–æ–∑–¥–∞–Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é: {e}")
            
            # –®–∞–≥ 3: –ê—Ç–æ–º–∞—Ä–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ –æ—Å–Ω–æ–≤–Ω–æ–π
            self._atomic_save(self.checkpoint_temp, self.checkpoint_file)
            
            # –®–∞–≥ 4: –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if os.path.exists(self.checkpoint_temp):
                try:
                    os.remove(self.checkpoint_temp)
                except Exception:
                    pass
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            self.state = CheckpointState.from_dict(checkpoint_data)
            self.checksum = checksum
            self.last_save = current_time
            self.save_count += 1
            
            # –û—á–∏—â–∞–µ–º –∫—ç—à
            self._cache.clear()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_stats('save')
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            if completion_condition:
                logger.info(f"üíæ –§–∏–Ω–∞–ª—å–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {processed_lines:,} –∏–∑ {total_lines:,} –∑–∞–ø–∏—Å–µ–π")
            elif records_condition:
                logger.info(f"üíæ –ß–µ–∫–ø–æ–∏–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω (–∫–∞–∂–¥—ã–µ {Config.CHECKPOINT_INTERVAL:,}): {processed_lines:,} –∑–∞–ø–∏—Å–µ–π")
            elif time_condition:
                logger.debug(f"üíæ –ê–≤—Ç–æ—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–∫–∞–∂–¥—ã–µ 60 —Å–µ–∫): {processed_lines:,} –∑–∞–ø–∏—Å–µ–π")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            if os.path.exists(self.checkpoint_temp):
                try:
                    os.remove(self.checkpoint_temp)
                except Exception:
                    pass
            
            return False
    
    def clear_checkpoint(self) -> int:
        """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã —á–µ–∫–ø–æ–∏–Ω—Ç–∞"""
        files_to_remove = [
            self.checkpoint_file,
            self.checkpoint_backup,
            self.checkpoint_temp,
            self.checkpoint_archive
        ]
        
        removed_count = 0
        for file_path in files_to_remove:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    removed_count += 1
                    logger.debug(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {file_path}")
                except Exception as e:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {file_path}: {e}")
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.state = None
        self.checksum = None
        self.last_save = 0.0
        self._cache.clear()
        
        if removed_count > 0:
            logger.info(f"–û—á–∏—â–µ–Ω–æ {removed_count} —Ñ–∞–π–ª–æ–≤ —á–µ–∫–ø–æ–∏–Ω—Ç–∞")
        
        return removed_count
    
    def should_save_checkpoint(self, processed_since_last: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç"""
        return processed_since_last >= Config.CHECKPOINT_INTERVAL
    
    def get_checkpoint_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —á–µ–∫–ø–æ–∏–Ω—Ç–µ"""
        if not self.state:
            return {
                "exists": False,
                "file_path": self.checkpoint_file,
                "backup_exists": os.path.exists(self.checkpoint_backup)
            }
        
        info = self.state.to_dict()
        info["exists"] = True
        info["file_path"] = self.checkpoint_file
        info["backup_exists"] = os.path.exists(self.checkpoint_backup)
        info["save_count"] = self.save_count
        info["checksum"] = self.checksum
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        if os.path.exists(self.checkpoint_file):
            try:
                info["file_size"] = os.path.getsize(self.checkpoint_file)
                info["file_mtime"] = os.path.getmtime(self.checkpoint_file)
                info["file_ctime"] = os.path.getctime(self.checkpoint_file)
            except Exception:
                pass
        
        return info
    
    def get_progress_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not self.state:
            return {"has_checkpoint": False}
        
        info = self.get_checkpoint_info()
        info["has_checkpoint"] = True
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫–æ—Ä–æ—Å—Ç–∏
        if self.state.timestamp > 0 and self.state.processed_lines > 0:
            elapsed_hours = self.state.age_hours
            
            if elapsed_hours > 0:
                records_per_hour = self.state.processed_lines / elapsed_hours
                info["records_per_hour"] = int(records_per_hour)
                info["elapsed_hours"] = round(elapsed_hours, 1)
                
                # –ü—Ä–æ–≥–Ω–æ–∑ –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                if self.state.total_lines > 0:
                    remaining = self.state.total_lines - self.state.processed_lines
                    if records_per_hour > 0:
                        hours_remaining = remaining / records_per_hour
                        info["hours_remaining"] = round(hours_remaining, 1)
                        info["eta_timestamp"] = time.time() + hours_remaining * 3600
        
        return info
    
    def validate_checkpoint(self, input_file: str) -> Tuple[bool, str]:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        
        Returns:
            Tuple[bool, str]: (–í–∞–ª–∏–¥–µ–Ω –ª–∏ —á–µ–∫–ø–æ–∏–Ω—Ç, –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ)
        """
        if not self.state:
            return False, "–ß–µ–∫–ø–æ–∏–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —á–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è —Ç–æ–≥–æ –∂–µ —Ñ–∞–π–ª–∞
        if self.state.file_name != os.path.basename(input_file):
            message = f"–ß–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è –¥—Ä—É–≥–æ–≥–æ —Ñ–∞–π–ª–∞: {self.state.file_name} != {os.path.basename(input_file)}"
            logger.warning(message)
            return False, message
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        if not os.path.exists(input_file):
            message = "–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
            logger.warning(message)
            return False, message
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ü–∏—é –≤ —Ñ–∞–π–ª–µ
        try:
            file_size = os.path.getsize(input_file)
            
            # –î–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –≤ –ø–æ–∑–∏—Ü–∏–∏ (1KB)
            if self.state.last_position > file_size + 1024:
                message = f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ —á–µ–∫–ø–æ–∏–Ω—Ç–µ: {self.state.last_position:,} > {file_size:,}"
                logger.warning(message)
                return False, message
            
            # –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è –±–ª–∏–∑–∫–∞ –∫ –∫–æ–Ω—Ü—É —Ñ–∞–π–ª–∞, —Å—á–∏—Ç–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π
            if file_size - self.state.last_position < 1024:  # –ú–µ–Ω—å—à–µ 1KB –æ—Å—Ç–∞–ª–æ—Å—å
                logger.info(f"–§–∞–π–ª –ø–æ—á—Ç–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø–æ–∑–∏—Ü–∏—è: {self.state.last_position:,} –∏–∑ {file_size:,}")
        
        except OSError as e:
            message = f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞: {e}"
            logger.warning(message)
            return False, message
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
        if self.state.total_lines < self.state.processed_lines:
            message = f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {self.state.processed_lines:,} > {self.state.total_lines:,}"
            logger.warning(message)
            return False, message
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è
        if self.state.is_expired(max_age_hours=168):  # 7 –¥–Ω–µ–π
            message = f"–ß–µ–∫–ø–æ–∏–Ω—Ç —É—Å—Ç–∞—Ä–µ–ª: {self.state.age_hours:.1f} —á–∞—Å–æ–≤"
            logger.warning(message)
            return False, message
        
        logger.info(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –≤–∞–ª–∏–¥–µ–Ω –¥–ª—è —Ñ–∞–π–ª–∞ {input_file}")
        return True, "–ß–µ–∫–ø–æ–∏–Ω—Ç –≤–∞–ª–∏–¥–µ–Ω"
    
    def archive_old_checkpoint(self, max_age_days: int = 30) -> bool:
        """–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç"""
        if not self.state:
            return False
        
        if self.state.age_hours <= max_age_days * 24:
            return False
        
        try:
            archive_dir = os.path.join(self.output_dir, "checkpoint_archive")
            os.makedirs(archive_dir, exist_ok=True)
            
            timestamp = datetime.fromtimestamp(self.state.timestamp).strftime("%Y%m%d_%H%M%S")
            archive_name = f"checkpoint_{self.state.file_name}_{timestamp}.json"
            archive_path = os.path.join(archive_dir, archive_name)
            
            # –ö–æ–ø–∏—Ä—É–µ–º —á–µ–∫–ø–æ–∏–Ω—Ç –≤ –∞—Ä—Ö–∏–≤
            if os.path.exists(self.checkpoint_file):
                shutil.copy2(self.checkpoint_file, archive_path)
                logger.info(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: {archive_path}")
                return True
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏ —á–µ–∫–ø–æ–∏–Ω—Ç–∞: {e}")
        
        return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–±–æ—Ç—ã –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤"""
        stats = self.stats.copy()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö
        stats['checkpoint_exists'] = os.path.exists(self.checkpoint_file)
        stats['backup_exists'] = os.path.exists(self.checkpoint_backup)
        stats['archive_exists'] = os.path.exists(self.checkpoint_archive)
        
        if os.path.exists(self.checkpoint_file):
            try:
                stats['checkpoint_size'] = os.path.getsize(self.checkpoint_file)
                stats['checkpoint_mtime'] = os.path.getmtime(self.checkpoint_file)
            except Exception:
                pass
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        if self.state:
            stats['current_state'] = {
                'processed_lines': self.state.processed_lines,
                'total_lines': self.state.total_lines,
                'progress_percent': self.state.progress_percent,
                'age_hours': self.state.age_hours,
                'batch_size': self.state.batch_size
            }
        
        stats['save_count'] = self.save_count
        stats['cache_size'] = len(self._cache)
        
        return stats
    
    def cleanup_temp_files(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        temp_files = [self.checkpoint_temp]
        
        for file_path in temp_files:
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.debug(f"–û—á–∏—â–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
                except Exception as e:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {file_path}: {e}")
    
    def __del__(self):
        """–î–µ—Å—Ç—Ä—É–∫—Ç–æ—Ä - –æ—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        try:
            self.cleanup_temp_files()
        except Exception:
            pass


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
class CheckpointUtils:
    """–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏"""
    
    @staticmethod
    def scan_for_checkpoints(directory: str) -> List[Dict[str, Any]]:
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤"""
        checkpoints = []
        
        try:
            for root, dirs, files in os.walk(directory):
                for file in files:
                    if file == Config.CHECKPOINT_FILE:
                        filepath = os.path.join(root, file)
                        try:
                            data = CheckpointUtils._safe_read_json(filepath)
                            if data:
                                checkpoints.append({
                                    'path': filepath,
                                    'directory': root,
                                    'file_name': data.get('file_name', ''),
                                    'processed_lines': data.get('processed_lines', 0),
                                    'total_lines': data.get('total_lines', 0),
                                    'timestamp': data.get('timestamp', 0),
                                    'progress_percent': (data.get('processed_lines', 0) / data.get('total_lines', 1) * 100) if data.get('total_lines', 0) > 0 else 0
                                })
                        except Exception as e:
                            logger.debug(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–∞ {filepath}: {e}")
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤: {e}")
        
        return checkpoints
    
    @staticmethod
    def _safe_read_json(filepath: str) -> Optional[Dict[str, Any]]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return None
    
    @staticmethod
    def merge_checkpoints(checkpoints: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤"""
        if not checkpoints:
            return None
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (—Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –ø–µ—Ä–≤—ã–π)
        checkpoints.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
        
        # –ë–µ—Ä–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π –≤–∞–ª–∏–¥–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç
        for checkpoint in checkpoints:
            if checkpoint.get('processed_lines', 0) > 0:
                return checkpoint
        
        return None


# –§–∞–±—Ä–∏—á–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
def create_checkpoint_manager(output_dir: str) -> CheckpointManager:
    """–°–æ–∑–¥–∞—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    os.makedirs(output_dir, exist_ok=True)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä
    manager = CheckpointManager(output_dir)
    
    # –°–∫–∞–Ω–∏—Ä—É–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å—Ç–∞—Ä—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
    checkpoints = CheckpointUtils.scan_for_checkpoints(output_dir)
    if len(checkpoints) > 1:
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(checkpoints)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏")
    
    return manager